{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1c08a9-6046-41da-baf5-9c9ea48f5fdd",
   "metadata": {},
   "source": [
    "# 뉴스 헤드라인 분류하기 (SageMaker 버전)\n",
    "\n",
    "> 이 노트북은 세이지메이커 스튜디오의 `Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)` 커널에서 잘 작동합니다.\n",
    "\n",
    "이 예제에서는 사용자 정의 스크립트와 [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) 프레임워크를 사용하여 뉴스 헤드라인 분류 모델을 훈련합니다.\n",
    "\n",
    "이 \"SageMaker\" 노트북에서는 Amazon SageMaker 훈련 작업에서 모델을 훈련하고, 매니지드 실시간 추론 엔드포인트로 배포하는 방법을 보여드립니다.\n",
    "\n",
    "> ⚠️ 여기서는 여기 노트북 자체에서 훈련 및 추론을 실행하는 방법을 보여주는, 동반된 [\"Headline Classifier Local\" notebook](Headline%20Classifier%20Local.ipynb)을 이미 실행한 것으로 가정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57514090-30b2-46c3-bee6-cb013b2038cb",
   "metadata": {},
   "source": [
    "## 설치 및 설정\n",
    "\n",
    "로컬 노트북에서와 마찬가지로, 시작하기 전에 위젯 라이브러리가 설정되어 있는지 확인하겠습니다.\n",
    "\n",
    "🟢 하지만 **로컬 노트북과 달리** HF Transformers를 **설치할 필요가 없다**는 점에 유의하세요: 실제 훈련과 추론은 이 커널이 아닌 컨테이너화된 작업에서 이루어지기 때문입니다.\n",
    "\n",
    "> ℹ️ (실제로 동일한 커널 이미지와 동일한 인스턴스에서 여러 개의 세이지메이커 스튜디오 노트북을 시작하면 환경을 공유하게 됩니다: 따라서 로컬 노트북을 실행하고 동일한 커널을 선택했다고 가정하면 모든 것이 이미 설치되어 있습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2cc7de2-59b4-49a7-8823-6953e2531cea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets<8 in /opt/conda/lib/python3.9/site-packages (7.7.5)\n",
      "Requirement already satisfied: sagemaker<3,>2.140 in /opt/conda/lib/python3.9/site-packages (2.143.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (1.1.4)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.4 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (3.6.4)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (5.5.6)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (0.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (8.10.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (5.9.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (1.23.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (0.3.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (4.17.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (1.5.3)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (4.13.0)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (5.4.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (0.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.28 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (1.26.70)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (3.2.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (23.0)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (22.2.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (0.1.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (3.20.2)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (0.7.5)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker<3,>2.140) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.70 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker<3,>2.140) (1.29.70)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker<3,>2.140) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker<3,>2.140) (3.13.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8) (6.2)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8) (8.1.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (2.14.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (5.1.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.6.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (3.0.36)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.18.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker<3,>2.140) (1.16.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.9/site-packages (from widgetsnbextension~=3.6.4->ipywidgets<8) (6.5.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->sagemaker<3,>2.140) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->sagemaker<3,>2.140) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->sagemaker<3,>2.140) (2022.7.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker<3,>2.140) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker<3,>2.140) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker<3,>2.140) (0.70.14)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker<3,>2.140) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.9/site-packages (from schema->sagemaker<3,>2.140) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.70->boto3<2.0,>=1.26.28->sagemaker<3,>2.140) (1.26.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8) (0.8.3)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (21.3.0)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (5.8.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.16.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (7.2.10)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (24.0.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (3.1.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (5.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.5.6)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.17.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.5.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=4.0.0->ipywidgets<8) (0.2.6)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (2.2.1)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.9/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.5.0)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.2.2)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (6.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (4.12.0)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.0.5)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.7.1)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.2.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.5.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.2.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.1.2)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.9/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.16.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (21.2.0)\n",
      "Requirement already satisfied: jupyter-events>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.6.3)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (3.6.2)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.5.1)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.4.4)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.9/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.4)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.9/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.5.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.21)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.9/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.0.7)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.1.1)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.9/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.1.4)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.9/site-packages (from jsonschema->sagemaker<3,>2.140) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.9/site-packages (from jsonschema->sagemaker<3,>2.140) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.9/site-packages (from jsonschema->sagemaker<3,>2.140) (2.3)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.9/site-packages (from jsonschema->sagemaker<3,>2.140) (1.13)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.9/site-packages (from jsonschema->sagemaker<3,>2.140) (1.2.0)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from isoduration->jsonschema->sagemaker<3,>2.140) (1.2.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"ipywidgets<8\" \"sagemaker>2.140,<3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e5d2d-d062-468f-96dc-d51018cc2450",
   "metadata": {},
   "source": [
    "설치가 완료되면 나머지 노트북에서 사용할 라이브러리와 Python 내장 기능을 로드합니다.\n",
    "\n",
    "[%autoreload magic](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html)은 로컬 .py 파일로 작업할 때 유용합니다. 셀을 실행할 때마다 라이브러리를 다시 로드하면 노트북 커널을 재시작할 필요 없이 로컬에서 편집/업데이트된 스크립트를 사용할 수 있기 때문입니다.\n",
    "\n",
    "🟢 이번에는 로컬 노트북에서는 필요 없던 **AWS libraries**를 사용하겠습니다:\n",
    "\n",
    "- `boto3`, [general-purpose AWS SDK for Python](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)\n",
    "- `sagemaker`,[high-level Python SDK for Amazon SageMaker](https://sagemaker.readthedocs.io/en/stable/)\n",
    "\n",
    "이 두 라이브러리는 모두 오픈소스이며, PyPI와 GitHub에 게시되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efbe751a-dce5-4dd1-b96c-35738d28fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import os  # Operating system utils e.g. file paths\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3  # General AWS SDK for Python\n",
    "import ipywidgets as widgets  # Interactive prediction widget\n",
    "import pandas as pd  # Utilities for working with data tables (dataframes)\n",
    "import sagemaker  # High-level Python SDK for Amazon SageMaker\n",
    "\n",
    "local_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b6e3e-1f50-4337-8339-fc05d71af52f",
   "metadata": {},
   "source": [
    "## 데이터셋 준비 및 업로드하기\n",
    "\n",
    "이 예에서는 [Registry of Open Data on AWS](https://registry.opendata.aws/fast-ai-nlp/)의 퍼블릭 리포지토리에서 **FastAi AG News** 데이터셋을 다운로드합니다. 이 데이터셋에는 뉴스 헤드라인과 그에 해당하는 토픽 클래스의 테이블이 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131a0145-9033-4112-a67f-5e229679229e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://fast-ai-nlp/ag_news_csv.tgz to data/ag_news_csv.tgz\n",
      "Done!\n",
      "CPU times: user 64 ms, sys: 22.5 ms, total: 86.4 ms\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download the AG News data from the Registry of Open Data on AWS.\n",
    "!mkdir -p {local_dir}\n",
    "!aws s3 cp s3://fast-ai-nlp/ag_news_csv.tgz {local_dir} --no-sign-request\n",
    "\n",
    "# Un-tar the AG News data.\n",
    "!tar zxf {local_dir}/ag_news_csv.tgz -C {local_dir}/ --strip-components=1 --no-same-owner\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba225c-14bd-4941-8fa0-a68fe7f5fe6f",
   "metadata": {},
   "source": [
    "데이터를 다운로드하고 추출한 후 아래와 같이 몇 가지 예를 살펴볼 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5369b9a2-c6f8-46ce-9b98-9451817be488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86110</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>Oracle to drop PeopleSoft suit if tender fails</td>\n",
       "      <td>Oracle Corp. notified Delaware's Court of Chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74390</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>NTT DoCoMo, IBM, Intel team to secure mobile d...</td>\n",
       "      <td>With an eye towards making mobile devices and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77491</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>Election Is Crunch Time for U.S. Secret Service</td>\n",
       "      <td>With just days to go before the U.S. president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27497</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Former Celtic striker Larsson on Barcelona bench</td>\n",
       "      <td>Henrik Larsson was left on the bench by Barcel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47492</th>\n",
       "      <td>World</td>\n",
       "      <td>Four Suicides Linked to Child Porn Probe (AP)</td>\n",
       "      <td>AP - The government will press on with a child...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CATEGORY                                              TITLE  \\\n",
       "86110  Sci/Tech     Oracle to drop PeopleSoft suit if tender fails   \n",
       "74390  Sci/Tech  NTT DoCoMo, IBM, Intel team to secure mobile d...   \n",
       "77491  Sci/Tech    Election Is Crunch Time for U.S. Secret Service   \n",
       "27497    Sports   Former Celtic striker Larsson on Barcelona bench   \n",
       "47492     World      Four Suicides Linked to Child Porn Probe (AP)   \n",
       "\n",
       "                                                 CONTENT  \n",
       "86110  Oracle Corp. notified Delaware's Court of Chan...  \n",
       "74390  With an eye towards making mobile devices and ...  \n",
       "77491  With just days to go before the U.S. president...  \n",
       "27497  Henrik Larsson was left on the bench by Barcel...  \n",
       "47492  AP - The government will press on with a child...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"CATEGORY\", \"TITLE\", \"CONTENT\"]\n",
    "# we use the train.csv only\n",
    "df = pd.read_csv(f\"{local_dir}/train.csv\", names=column_names, header=None, delimiter=\",\")\n",
    "# shuffle the DataFrame rows\n",
    "df = df.sample(frac=1, random_state=1337)\n",
    "\n",
    "# Make the (1-indexed) category classes more readable:\n",
    "class_names = [\"Other\", \"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "idx2label = {ix: name for ix, name in enumerate(class_names)}\n",
    "label2idx = {name: ix for ix, name in enumerate(class_names)}\n",
    "\n",
    "df = df.replace({\"CATEGORY\": idx2label})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f56818-09f1-48fc-bd5b-21530e7ef9c5",
   "metadata": {},
   "source": [
    "이번 연습에서는 **아래의 값만 사용하겠습니다**:\n",
    "\n",
    "- 뉴스 기사의 **title** (Headline)을 인풋으로 사용합니다.\n",
    "- 예측할 목표 변수로 **category**를 사용합니다.\n",
    "\n",
    "이 데이터 세트에는 아래와 같이 4개의 균등하게 분포된 주제 클래스가 포함되어 있습니다.\n",
    "\n",
    "> ℹ️ **'Other'는 어떻게 할까요?:** 원시 데이터 세트는 1~4 사이의 숫자로 범주를 나타내며, 우리의 모델은 0부터 시작하는 숫자를 예상하기 때문에, 데이터 준비를 단순하게 유지하고 클래스의 혼란스러운 추가 숫자 표현을 피하기 위해 사용하지 않는 'Other' 클래스를 삽입했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a70b377-ee49-4780-8b32-57db4ee149ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sci/Tech    30000\n",
       "Sports      30000\n",
       "World       30000\n",
       "Business    30000\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CATEGORY\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db84ebf-e768-4d32-ad34-fc627cfe9597",
   "metadata": {},
   "source": [
    "지금까지 새로운 것은 없습니다...\n",
    "\n",
    "🟢 세이지메이커 훈련의 주요 차이점은 [훈련 작업에서 액세스할 수 있는 곳에](https://docs.aws.amazon.com/sagemaker/latest/dg/model-access-training-data.html) 데이터셋을 **업로드**해야 한다는 것입니다.\n",
    "\n",
    "여기서는 [SageMaker default bucket](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-ex-bucket.html)을 사용하여 데이터를 [Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html)에 업로드하겠습니다. 원하는 경우 버킷과 폴더 접두사를 사용자 지정할 수 있습니다. 훈련 데이터와 테스트 데이터를 같은 폴더에 두 파일만 저장하지 말고 별도의 S3 폴더로 분리하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec896d2-e210-4987-aac5-d21d968816cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_s3_uri: s3://sagemaker-us-east-1-603420654815/sm101/news/train\n",
      "test_s3_uri: s3://sagemaker-us-east-1-603420654815/sm101/news/test\n"
     ]
    }
   ],
   "source": [
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "s3_prefix = \"sm101/news\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "s3.Bucket(bucket_name).upload_file(f\"{local_dir}/train.csv\", f\"{s3_prefix}/train/train.csv\")\n",
    "train_s3_uri = f\"s3://{bucket_name}/{s3_prefix}/train\"\n",
    "print(f\"train_s3_uri: {train_s3_uri}\")\n",
    "\n",
    "s3.Bucket(bucket_name).upload_file(f\"{local_dir}/test.csv\", f\"{s3_prefix}/test/test.csv\")\n",
    "test_s3_uri = f\"s3://{bucket_name}/{s3_prefix}/test\"\n",
    "print(f\"test_s3_uri: {test_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628acab-0b0b-4b77-9800-8dc154c55249",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 훈련 매개변수 정의\n",
    "\n",
    "[Hugging Face Hub](https://huggingface.co/models)에서 (비교적 작은) 사전 훈련된 모델을 미세 조정하고, 낮은 수준의 훈련 루프를 처음부터 작성하는 대신 높은 수준의 [Trainer API](https://huggingface.co/docs/transformers/main_classes/trainer)를 사용할 것입니다.\n",
    "\n",
    "🟢 훈련 스크립트는 궁극적으로 이전과 비슷한 파라미터를 사용하지만 이번에는 **훈련 작업 API**를 통해 전달할 것입니다.\n",
    "\n",
    "여기 노트북에서 **JSON 직렬화 가능 매개변수**를 정의한 다음, 이를 사용하여 나중에 `transformers.TrainingArguments`를 빌드할 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21191118-ecc3-4b42-bf84-76882582ce31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'amazon/bort',\n",
       " 'class_names': 'Other,World,Sports,Business,Sci/Tech',\n",
       " 'num_train_epochs': 3,\n",
       " 'per_device_train_batch_size': 32,\n",
       " 'per_device_eval_batch_size': 64,\n",
       " 'warmup_steps': 500}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"model_id\": \"amazon/bort\",  # ID of the pre-trained model to start from\n",
    "    \"class_names\": \",\".join(class_names),  # Comma-separated list of category names\n",
    "    \"num_train_epochs\": 3,  # This time, we'll actually train for a full 3 epochs\n",
    "    \"per_device_train_batch_size\": 32,  # Note this is higher than we could set on local hardware\n",
    "    \"per_device_eval_batch_size\": 64,  # Note this is higher than we could set on local hardware\n",
    "    \"warmup_steps\": 500,  # Higher than we could set with the reduced local training\n",
    "}\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a37d97-07f7-4985-8b6a-19aa751d1ab4",
   "metadata": {},
   "source": [
    "# 메트릭 정의\n",
    "\n",
    "학습된 모델의 품질을 측정하는 방법을 정의하고 이 정보를 세이지메이커에 표시하여 메트릭 로깅, 자동 모델 튜닝 및 리더보드와 같은 기능을 활성화하고자 합니다.\n",
    "\n",
    "🟢 평소와 같이 훈련 코드가 메트릭을 프린트하도록 하고, [use regular expressions](https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html#define-train-metrics)을 통해 세이지메이커가 작업 로그에서 구조화된 메트릭을 스크랩하는 방법을 정의하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "935497f0-1b44-450e-a725-8b65509231a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Name': 'Epoch', 'Regex': \"'epoch': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Train:Loss', 'Regex': \"'loss': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Train:LearningRate', 'Regex': \"'learning_rate': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Loss', 'Regex': \"'eval_loss': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Accuracy', 'Regex': \"'eval_accuracy': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:F1', 'Regex': \"'eval_f1': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Precision',\n",
       "  'Regex': \"'eval_precision': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Recall', 'Regex': \"'eval_recall': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Runtime', 'Regex': \"'eval_runtime': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:SamplesPerSecond',\n",
       "  'Regex': \"'eval_samples_per_second': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:StepsPerSecond',\n",
       "  'Regex': \"'eval_steps_per_second': ([0-9\\\\.\\\\-e]+)\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_definitions = [\n",
    "    {\"Name\": \"Epoch\", \"Regex\": r\"'epoch': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Train:Loss\", \"Regex\": r\"'loss': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Train:LearningRate\", \"Regex\": r\"'learning_rate': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Loss\", \"Regex\": r\"'eval_loss': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Accuracy\", \"Regex\": r\"'eval_accuracy': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:F1\", \"Regex\": r\"'eval_f1': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Precision\", \"Regex\": r\"'eval_precision': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Recall\", \"Regex\": r\"'eval_recall': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Runtime\", \"Regex\": r\"'eval_runtime': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:SamplesPerSecond\", \"Regex\": r\"'eval_samples_per_second': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:StepsPerSecond\", \"Regex\": r\"'eval_steps_per_second': ([0-9\\.\\-e]+)\"},\n",
    "]\n",
    "metric_definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2df25-93e0-4f15-89de-844b291d6862",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 세이지메이커에서 모델 훈련 및 검증하기\n",
    "\n",
    "이번에는 노트북 자체와 별도의 인스턴스에서 훈련 프로세스를 실행하기 위해 [SageMaker training job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html)을 생성하겠습니다: 이를 통해 수명이 긴 노트북 환경과 독립적으로 임시 훈련 인프라의 크기를 적절히 조정할 수 있습니다.\n",
    "\n",
    "🟢 노트북에서 실제 훈련 코드를 **[scripts/train.py](scripts/train.py)**에 팩터링했으며, 이 스크립트에서 모델을 훈련하고 배포하기 위해 미리 빌드된 [세이지메이커 파이썬 SDK를 통한 허깅 페이스 프레임워크 컨테이너](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html)를 사용할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70294b2-ee08-4c90-a7f7-d88ed52e07cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Amazon SageMaker가 사전 빌드된 컨테이너로 스크립트를 실행시키는 방법 \n",
    "\n",
    "AWS는 주요 머신러닝 프레임워크에서 프로젝트를 빠르게 구축할 수 있도록 사전 패키지된 Docker 이미지 세트를 제공합니다:[SageMaker Framework Containers](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers-prebuilt.html).\n",
    "\n",
    "이 컨테이너는 GPU 드라이버, 서빙 스택 구현, 핵심 라이브러리 등과 같은 기본 설정을 처리하므로 훈련 프로세스 및 추론 동작 오버라이드를 위한 Python 스크립트만 간단히 삽입하면 됩니다. 심지어 컨테이너 이미지에 빌드할 필요 없이 시작 시 동적으로 설치할 추가 종속성을 지정하는 *requirements.txt* 파일을 제공할 수도 있습니다.\n",
    "\n",
    "**따라서 첫 번째 작업은 스크립트와 런타임 간의 인터페이스**를 이해하는 것입니다: 스크립트가 입력 데이터를 어떻게 읽을 것인가? 매개변수는? 결과를 어디에 저장해야 할까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a6b41-a844-42e2-b3a7-d07252a394f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 훈련 중인 컨테이너\n",
    "\n",
    "훈련 작업 컨테이너가 시작되면 **코드 및 인풋 데이터**가 `/opt/ml` 디렉터리 아래의 **로컬 파일**로 다운로드됩니다. 또한 아래와 같이 학습된 모델과 기타 파일 출력을 로컬 파일 시스템에 저장합니다:\n",
    "\n",
    "\n",
    "```\n",
    "    /opt/ml\n",
    "    |-- code\n",
    "    |   `-- <our script(s)>\n",
    "    |-- input\n",
    "    |   |-- config\n",
    "    |   |   |-- hyperparameters.json\n",
    "    |   |   `-- resourceConfig.json\n",
    "    |   `-- data\n",
    "    |       `-- <channel_name>\n",
    "    |           `-- <input data>\n",
    "    |-- model\n",
    "    |   `-- <model files>\n",
    "    `-- output\n",
    "        `-- failure\n",
    "```\n",
    "\n",
    "\n",
    "##### 인풋\n",
    "\n",
    "* `/opt/ml/input/config`에는 프로그램 실행 방식을 제어하는 정보가 들어 있습니다. `hyperparameters.json`은 하이퍼파라미터 이름을 값으로 변환한 JSON 형식의 딕셔너리입니다. 이 값은 항상 문자열이므로 변환해야 할 수도 있습니다. `resourceConfig.json`은 분산 학습에 사용되는 네트워크 레이아웃을 설명하는 JSON 형식의 파일입니다. scikit-learn은 분산 학습을 지원하지 않으므로 여기서는 무시하겠습니다.\n",
    "* (파일 모드의 경우) `/opt/ml/input/data/<channel_name>/`에는 해당 채널의 인풋 데이터가 포함됩니다. 채널은 CreateTrainingJob 호출에 따라 생성되지만 일반적으로 채널이 알고리즘이 예상하는 것과 일치하는 것이 중요합니다. 각 채널의 파일은 S3 키 구조로 표시된 트리 구조를 유지하면서 S3에서 이 디렉토리로 복사됩니다. \n",
    "* (파이프 모드의 경우) `/opt/ml/input/data/<channel_name>_<epoch_number>`는 주어진 에포크에 대한 파이프입니다. 에포크는 0에서 시작하여 읽을 때마다 하나씩 올라갑니다. 실행할 수 있는 에포크 수에는 제한이 없지만 다음 에포크를 읽기 전에 각 파이프를 닫아야 합니다.\n",
    "\n",
    "\n",
    "##### 아웃풋\n",
    "\n",
    "* `/opt/ml/model/`은 알고리즘이 생성하는 모델을 작성하는 디렉토리입니다. 모델은 원하는 모든 형식이 가능합니다. 단일 파일 또는 전체 디렉토리 트리가 될 수 있습니다. 세이지메이커는 이 디렉토리에 있는 모든 파일을 압축된 타르 아카이브 파일로 패키징합니다. 이 파일은 `DescribeTrainingJob` 결과에서 반환된 S3 위치에서 사용할 수 있습니다.\n",
    "* `/opt/ml/output`은 알고리즘이 작업이 실패한 이유를 설명하는 `failure` 파일을 작성할 수 있는 디렉터리입니다. 이 파일의 내용은 `DescribeTrainingJob` 결과의 `FailureReason` 필드에 반환됩니다. 성공한 작업의 경우 무시되므로 이 파일을 작성할 이유가 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591f290d-7eb9-4acf-b9d4-5df4a06e3f57",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 추가 정보\n",
    "\n",
    "자세한 내용은 다음을 참조하세요:\n",
    "\n",
    "- [SageMaker Python SDK guide for Hugging Face](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html) 및 HF 프레임워크 클래스에 대한 [API doc](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html)를 참조하세요. (PyTorch의 해당 페이지도 유용할 수 있습니다).\n",
    "- 기본 컨테이너 이미지를 정의하는 GitHub의 [AWS Deep Learning Containers repository](https://github.com/aws/deep-learning-containers).\n",
    "- 훈련 및 서비스를 위한 프레임워크 코드에 대한 자세한 내용은 오픈 소스 [SageMaker Training Toolkit](https://github.com/aws/sagemaker-training-toolkit) 및 [SageMaker Inference Toolkit](https://github.com/aws/sagemaker-inference-toolkit)을 참조하세요. (일부 프레임워크는 이러한 툴킷의 변형을 사용합니다. 예: [sagemaker-pytorch-training-toolkit](https://github.com/aws/sagemaker-pytorch-training-toolkit))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d648ba-8214-423e-926d-1417d56e413c",
   "metadata": {},
   "source": [
    "### 작업 생성하기\n",
    "\n",
    "실제 [SageMaker CreateTrainingJob API](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html)에는 세이지메이커 파이썬 SDK의 상위 [high-level 'Estimator' classes](https://sagemaker.readthedocs.io/en/stable/overview.html)가 단순화하는 데 도움이 되는 몇 가지 하위 레벨 세부 정보가 필요합니다. 특히:\n",
    "\n",
    "- 정확한 컨테이너 이미지 URI를 지정하는 대신 선택한 프레임워크 및 버전에 따라 SDK가 이를 찾아줍니다.\n",
    "- SDK는 `scripts` 번들을 투명하게 압축하여 S3에 업로드하고, 거기에서 로드하도록 훈련 작업을 구성합니다.\n",
    "\n",
    "먼저, 작업을 구성하는 `estimator` 객체와 이 작업이 실행될 인프라(컴퓨팅 인스턴스 수와 유형)를 생성합니다:\n",
    "\n",
    "> ℹ️ 사용자를 대신하여 작업을 실행하는 다른 서비스와 마찬가지로, 훈련 작업은 [IAM 역할](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)을 설정하여 S3의 인풋 훈련 데이터와 같은 리소스에 액세스할 수 있도록 합니다. 세이지메이커 노트북 자체는 이미 가정된 역할로 실행되므로, 단순화를 위해 훈련 작업 역할을 노트북 역할과 동일하게 설정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f6dbe0-6c13-4199-b219-5fe4e4543d03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.estimator import HuggingFace as HuggingFaceEstimator\n",
    "\n",
    "nb_role = sagemaker.get_execution_role()\n",
    "\n",
    "estimator = HuggingFaceEstimator(\n",
    "    transformers_version=\"4.26\",\n",
    "    pytorch_version=\"1.13\",\n",
    "    py_version=\"py39\",\n",
    "\n",
    "    source_dir=\"scripts\",  # Local folder where fine-tuning script is stored\n",
    "    entry_point=\"train.py\",  # Actual script the training job should run\n",
    "\n",
    "    base_job_name=\"news-classifier\",  # Prefix for the training job name (timestamp will be added)\n",
    "    instance_count=1,  # Number of instances train on (need to prepare your script for using >1!)\n",
    "    instance_type=\"ml.p3.2xlarge\",  # Type of compute instance to use: p* and g* include GPUs\n",
    "    role=nb_role,  # IAM role the job will use to access AWS resources (e.g. data on S3)\n",
    "\n",
    "    hyperparameters= hyperparameters,   # Training job parameters, as we set up earlier\n",
    "    metric_definitions=metric_definitions,  # RegEx to extract metric data from training job logs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c804ca-7678-4277-9f74-f3851d7efa5a",
   "metadata": {},
   "source": [
    "구성이 완료되면 `estimator.fit()`을 실행하고 인풋 데이터 위치를 지정하여 실제 훈련 작업을 시작할 수 있습니다.\n",
    "\n",
    "데이터 인풋 '채널'의 수, 이름 및 유형은 [사용자에게 달려 있습니다](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html#sagemaker-CreateTrainingJob-request-InputDataConfig): 노트북이 스크립트에서 예상하는 것과 동일한 채널을 구성하는지 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f351c2e7-70ee-4d02-8b28-b1792073b8df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: news-classifier-2023-03-30-16-09-35-281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 16:09:37 Starting - Starting the training job...\n",
      "2023-03-30 16:10:02 Starting - Preparing the instances for training......\n",
      "2023-03-30 16:11:07 Downloading - Downloading input data...\n",
      "2023-03-30 16:11:27 Training - Downloading the training image..................\n",
      "2023-03-30 16:14:28 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,115 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,134 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,146 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,149 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,414 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,447 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,479 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,492 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"class_names\": \"Other,World,Sports,Business,Sci/Tech\",\n",
      "        \"model_id\": \"amazon/bort\",\n",
      "        \"num_train_epochs\": 3,\n",
      "        \"per_device_eval_batch_size\": 64,\n",
      "        \"per_device_train_batch_size\": 32,\n",
      "        \"warmup_steps\": 500\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"news-classifier-2023-03-30-16-09-35-281\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-603420654815/news-classifier-2023-03-30-16-09-35-281/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"class_names\":\"Other,World,Sports,Business,Sci/Tech\",\"model_id\":\"amazon/bort\",\"num_train_epochs\":3,\"per_device_eval_batch_size\":64,\"per_device_train_batch_size\":32,\"warmup_steps\":500}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-603420654815/news-classifier-2023-03-30-16-09-35-281/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"class_names\":\"Other,World,Sports,Business,Sci/Tech\",\"model_id\":\"amazon/bort\",\"num_train_epochs\":3,\"per_device_eval_batch_size\":64,\"per_device_train_batch_size\":32,\"warmup_steps\":500},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"news-classifier-2023-03-30-16-09-35-281\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-603420654815/news-classifier-2023-03-30-16-09-35-281/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--class_names\",\"Other,World,Sports,Business,Sci/Tech\",\"--model_id\",\"amazon/bort\",\"--num_train_epochs\",\"3\",\"--per_device_eval_batch_size\",\"64\",\"--per_device_train_batch_size\",\"32\",\"--warmup_steps\",\"500\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_CLASS_NAMES=Other,World,Sports,Business,Sci/Tech\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=amazon/bort\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_EVAL_BATCH_SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_STEPS=500\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 train.py --class_names Other,World,Sports,Business,Sci/Tech --model_id amazon/bort --num_train_epochs 3 --per_device_eval_batch_size 64 --per_device_train_batch_size 32 --warmup_steps 500\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:14:47.624: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:47,631 root         INFO     Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:47,661 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mDownloading (…)okenizer_config.json:   0%|          | 0.00/1.04k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)okenizer_config.json: 100%|██████████| 1.04k/1.04k [00:00<00:00, 129kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json: 100%|██████████| 507/507 [00:00<00:00, 90.3kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 85.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 55.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)cial_tokens_map.json: 100%|██████████| 772/772 [00:00<00:00, 298kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/255M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▍         | 10.5M/255M [00:00<00:06, 37.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 21.0M/255M [00:01<00:14, 15.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 31.5M/255M [00:01<00:10, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▋        | 41.9M/255M [00:01<00:07, 29.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██        | 52.4M/255M [00:01<00:05, 39.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▍       | 62.9M/255M [00:02<00:05, 37.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▊       | 73.4M/255M [00:02<00:05, 36.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 83.9M/255M [00:02<00:04, 34.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 94.4M/255M [00:03<00:04, 33.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████      | 105M/255M [00:03<00:03, 40.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▌     | 115M/255M [00:03<00:04, 34.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▉     | 126M/255M [00:03<00:03, 41.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 136M/255M [00:04<00:03, 37.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 147M/255M [00:04<00:03, 33.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 157M/255M [00:04<00:02, 33.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 168M/255M [00:05<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|██████▉   | 178M/255M [00:05<00:02, 34.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 189M/255M [00:05<00:01, 34.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 199M/255M [00:06<00:01, 30.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 210M/255M [00:06<00:01, 33.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 220M/255M [00:06<00:01, 31.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|█████████ | 231M/255M [00:07<00:00, 28.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 241M/255M [00:07<00:00, 28.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▊| 252M/255M [00:07<00:00, 28.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";: 100%|██████████| 255M/255M [00:07<00:00, 32.0MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at amazon/bort were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at amazon/bort and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at amazon/bort were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at amazon/bort and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:15:01,281 - datasets.builder - WARNING - Using custom data configuration default-b3addd5ffbf832ab\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-b3addd5ffbf832ab/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\u001b[0m\n",
      "\u001b[34mDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-b3addd5ffbf832ab/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:15:04,728 - __main__ - INFO - Loaded train_dataset length is: 120000\u001b[0m\n",
      "\u001b[34m2023-03-30 16:15:04,786 - datasets.builder - WARNING - Using custom data configuration default-74fbc9d322077d2a\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-74fbc9d322077d2a/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\u001b[0m\n",
      "\u001b[34mDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-74fbc9d322077d2a/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:15:05,089 - __main__ - INFO - Loaded test_dataset length is: 7600\u001b[0m\n",
      "\u001b[34mUsing cuda_amp half precision backend\u001b[0m\n",
      "\u001b[34mUsing cuda_amp half precision backend\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m***** Running training *****\u001b[0m\n",
      "\u001b[34mNum examples = 120000\n",
      "  Num Epochs = 3\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 120000\n",
      "  Num Epochs = 3\u001b[0m\n",
      "\u001b[34mInstantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11250\u001b[0m\n",
      "\u001b[34mInstantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11250\u001b[0m\n",
      "\u001b[34mNumber of trainable parameters = 76162053\u001b[0m\n",
      "\u001b[34mNumber of trainable parameters = 76162053\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.148: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-03-30 16:15:07,154 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.189 algo-1:49 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.228 algo-1:49 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.228 algo-1:49 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.229 algo-1:49 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.230 algo-1:49 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.230 algo-1:49 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mYou're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34mYou're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m{'loss': 1.3377, 'learning_rate': 5e-05, 'epoch': 0.13}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7977, 'learning_rate': 4.7674418604651164e-05, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6202, 'learning_rate': 4.5348837209302326e-05, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5383, 'learning_rate': 4.302325581395349e-05, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5191, 'learning_rate': 4.0697674418604655e-05, 'epoch': 0.67}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4978, 'learning_rate': 3.837209302325582e-05, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4733, 'learning_rate': 3.604651162790698e-05, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\u001b[0m\n",
      "\u001b[34mBatch size = 64\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.44027823209762573, 'eval_accuracy': 0.8527631578947369, 'eval_f1': 0.8527631578947369, 'eval_precision': 0.8527631578947369, 'eval_recall': 0.8527631578947369, 'eval_runtime': 1.7576, 'eval_samples_per_second': 4324.056, 'eval_steps_per_second': 67.706, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-3750\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-3750\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-3750/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-3750/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-3750/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-3750/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-3750/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-3750/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-3750/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-3750/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3862, 'learning_rate': 3.372093023255814e-05, 'epoch': 1.07}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3425, 'learning_rate': 3.13953488372093e-05, 'epoch': 1.2}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3366, 'learning_rate': 2.9069767441860467e-05, 'epoch': 1.33}\u001b[0m\n",
      "\u001b[34m{'loss': 0.33, 'learning_rate': 2.674418604651163e-05, 'epoch': 1.47}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3242, 'learning_rate': 2.441860465116279e-05, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3279, 'learning_rate': 2.2097674418604654e-05, 'epoch': 1.73}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3381, 'learning_rate': 1.9772093023255812e-05, 'epoch': 1.87}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3274, 'learning_rate': 1.7446511627906977e-05, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\u001b[0m\n",
      "\u001b[34mNum examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mBatch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4255436062812805, 'eval_accuracy': 0.8586842105263158, 'eval_f1': 0.8586842105263158, 'eval_precision': 0.8586842105263158, 'eval_recall': 0.8586842105263158, 'eval_runtime': 1.7699, 'eval_samples_per_second': 4293.948, 'eval_steps_per_second': 67.234, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-7500\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-7500\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-7500/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-7500/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-7500/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-7500/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-7500/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-7500/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-7500/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-7500/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2252, 'learning_rate': 1.5120930232558139e-05, 'epoch': 2.13}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2288, 'learning_rate': 1.2800000000000001e-05, 'epoch': 2.27}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2309, 'learning_rate': 1.0474418604651164e-05, 'epoch': 2.4}\u001b[0m\n",
      "\u001b[34m{'loss': 0.234, 'learning_rate': 8.148837209302326e-06, 'epoch': 2.53}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2204, 'learning_rate': 5.823255813953488e-06, 'epoch': 2.67}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2291, 'learning_rate': 3.502325581395349e-06, 'epoch': 2.8}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2295, 'learning_rate': 1.1767441860465117e-06, 'epoch': 2.93}\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.44188404083251953, 'eval_accuracy': 0.861578947368421, 'eval_f1': 0.861578947368421, 'eval_precision': 0.861578947368421, 'eval_recall': 0.861578947368421, 'eval_runtime': 1.6449, 'eval_samples_per_second': 4620.359, 'eval_steps_per_second': 72.345, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-11250\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-11250\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-11250/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-11250/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-11250/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-11250/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-11250/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-11250/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-11250/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-11250/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from /tmp/transformers/checkpoints/checkpoint-11250 (score: 0.861578947368421).\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from /tmp/transformers/checkpoints/checkpoint-11250 (score: 0.861578947368421).\u001b[0m\n",
      "\u001b[34m{'train_runtime': 426.9917, 'train_samples_per_second': 843.108, 'train_steps_per_second': 26.347, 'train_loss': 0.408696252102322, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.44188404083251953, 'eval_accuracy': 0.861578947368421, 'eval_f1': 0.861578947368421, 'eval_precision': 0.861578947368421, 'eval_recall': 0.861578947368421, 'eval_runtime': 1.64, 'eval_samples_per_second': 4634.054, 'eval_steps_per_second': 72.56, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m***** Eval results *****\u001b[0m\n",
      "\u001b[34m2023-03-30 16:22:16,931 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:22:16,931 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:22:16,931 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-03-30 16:22:21 Uploading - Uploading generated training model\n",
      "2023-03-30 16:23:32 Completed - Training job completed\n",
      "Training seconds: 745\n",
      "Billable seconds: 745\n",
      "CPU times: user 4.93 s, sys: 191 ms, total: 5.13 s\n",
      "Wall time: 14min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimator.fit(\n",
    "    {\n",
    "        \"train\": train_s3_uri,\n",
    "        \"test\": test_s3_uri,\n",
    "    },\n",
    "    wait=True,  # Wait for the training to complete (default=True)\n",
    "    logs=True,  # Stream training job logs to the notebook (default=True, requires wait=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c940a-77cc-472e-8263-fe2a0c236f9b",
   "metadata": {},
   "source": [
    "> ⏰ 이 훈련 작업은 완료하는 데 10분 정도 걸리지만 '로컬' 모델보다 훨씬 더 높은 정확도에 도달해야 합니다.\n",
    "\n",
    "트레이닝 자체는 소형 CPU 전용 노트북이 아닌 GPU 가속 인스턴스에서 실행되므로 이전의 '로컬' 예제보다 훨씬 빨라야 합니다. 하지만 인프라를 프로비저닝하고 작업을 시작하는 데는 몇 분 정도 소요될 수 있습니다.\n",
    "\n",
    "[아마존 세이지메이커용 AWS Console](https://console.aws.amazon.com/sagemaker/home?#/jobs)의 *Training jobs* 페이지와 세이지메이커 스튜디오의 **Experiments** UI(왼쪽 사이드바의 🏠 **홈** 버튼에서)에서도 현재 및 과거 작업의 상태를 확인할 수 있습니다.\n",
    "\n",
    "🟢 대기 및 로그 스트리밍의 기본 동작은 로컬과 유사한 경험을 제공하지만, 훈련 작업은 노트북에 의존하지 않습니다:\n",
    "\n",
    "- 노트북의 연결을 끊거나 종료해도 훈련 작업은 계속 진행됩니다.\n",
    "- `wait=False`를 설정하면 노트북에서 여러 개의 트레이닝 작업을 동시에 시작할 수 있습니다.\n",
    "- 재시작한 노트북을 이전 훈련 작업에 연결해야 하는 경우, 아래와 같이 훈련 작업 이름으로 `.attach()`하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6156d24-b630-4df3-a912-18cf1ed002f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-03-30 16:23:32 Starting - Preparing the instances for training\n",
      "2023-03-30 16:23:32 Downloading - Downloading input data\n",
      "2023-03-30 16:23:32 Training - Training image download completed. Training in progress.\n",
      "2023-03-30 16:23:32 Uploading - Uploading generated training model\n",
      "2023-03-30 16:23:32 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "# estimator = HuggingFaceEstimator.attach(\"news-classifier-2023-03-30-16-09-35-281\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf511626-84a6-4579-9a77-39d0fc048cc9",
   "metadata": {},
   "source": [
    "훈련 작업이 완료되면 컨테이너의 모델 아웃풋 폴더의 내용이 자동으로 S3에 아카이브됩니다.\n",
    "\n",
    "아래 그림과 같이 이 파일을 참조할 수 있으며, SageMaker 외부에서 학습된 모델을 유사한 타르볼 형식으로 준비하여 배포용으로 가져올 수도 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c490cab6-7ae5-450d-b7ae-ff8156e5817d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-603420654815/news-classifier-2023-03-30-16-09-35-281/output/model.tar.gz'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.latest_training_job.describe()[\"ModelArtifacts\"][\"S3ModelArtifacts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2150a348-e0c3-40c7-9d5e-14c8c6986033",
   "metadata": {},
   "source": [
    "## 추론에 모델 사용\n",
    "\n",
    "모델이 학습되면 새로운 데이터에 대한 추론에 사용할 준비가 된 것입니다.\n",
    "\n",
    "세이지메이커는 [온디맨드 추론을 위한 모델 배포](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html) 또는 [배치 추론 작업 실행](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)을 위한 여러 가지 완전 관리형 옵션을 제공합니다.\n",
    "\n",
    "> ℹ️ **주의사항:** 사용 사례에 적합한 추론 옵션을 선택하세요 - 배치 데이터만 처리하려는 경우 실시간 엔드포인트를 배포할 필요가 없습니다!\n",
    ">\n",
    "> 지금까지 사용했던 것과 동일한 높은 수준의 SageMaker Python SDK를 통해 배치 추론을 실행하는 방법에 대한 자세한 내용은 [SageMaker 배치 변환 사용](https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-batch-transform)을 참조하십시오.\n",
    "\n",
    "이 예제에서는 모델을 [실시간 추론 엔드포인트](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)에 배포하여 온디맨드 방식으로 헤드라인을 분류할 수 있도록 하겠습니다.\n",
    "\n",
    "엔드포인트를 실행할 인프라 유형을 다시 지정하므로 시작하는 데 몇 분 정도 걸립니다. 이 테스트 엔드포인트는 트래픽을 매우 적게 처리하므로 더 작고 저렴한 인프라를 사용할 수 있으므로 훈련용과는 다른 유형의 인스턴스를 사용할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "795f1525-b0f1-449a-9c17-e3b587e77a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: news-classifier-2023-03-30-16-33-41-922\n",
      "INFO:sagemaker:Creating endpoint-config with name news-classifier-2023-03-30-16-33-41-922\n",
      "INFO:sagemaker:Creating endpoint with name news-classifier-2023-03-30-16-33-41-922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7322a7f0-e2c1-45ec-9a96-eb64036c8384",
   "metadata": {},
   "source": [
    "배포 후에는 [Amazon SageMaker용 AWS 콘솔](https://console.aws.amazon.com/sagemaker/home?#/endpoints)의 *Endpoints* 페이지와 세이지메이커 스튜디오 UI의 **Deployments > Endpoints** 섹션(왼쪽 사이드바의 🏠 **Home** 버튼에서)에서 엔드포인트를 찾을 수 있어야 합니다.\n",
    "\n",
    "훈련 작업과 마찬가지로 엔드포인트는 노트북 자체에서 분리되어 있습니다. 다음과 같이 이전에 배포된 엔드포인트에 노트북을 연결할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371515a-ed8a-41a2-87f8-3fdf63dcfb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.huggingface import HuggingFacePredictor\n",
    "# predictor = HuggingFacePredictor(\"news-classifier-2023-03-24-13-31-09-895\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e58b2-f792-46e1-b7a3-7613bb9f3184",
   "metadata": {},
   "source": [
    "### 이제 모델이 프로덕션 환경에서 RESTful API로 작동합니다!\n",
    "\n",
    "[Predictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html)는 여기서 모델을 메모리에 로드하지 않고 대신 배포된 엔드포인트에 대한 HTTPS API 호출을 래핑합니다.\n",
    "\n",
    "여기서는 Hugging Face 프레임워크에서 제공하는 기본 `application/json` 직렬화 지원을 사용하고 있지만, 프레임워크마다 기본 형식이 다르므로 사용자 정의 [serializers](https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html) 및 [deserializers](https://sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html)(client/`predictor` 측)와 사용자 정의 [`input_fn`s and `output_fn`s](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#process-model-input)(엔드포인트 컨테이너 측)를 사용하여 원하는 거의 모든 요청 또는 응답 형식을 설정할 수 있습니다: 자체 서빙 스택을 처음부터 작성할 필요가 없습니다.\n",
    "\n",
    "요청 역/직렬화 및 처리는 이미 [HuggingFacePredictor](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html#hugging-face-predictor)와 사전 구축된 추론 컨테이너에 의해 처리되므로, 노트북에서 배포된 모델을 호출하는 것은 로컬 인메모리 모델을 호출하는 것만큼이나 쉽습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d658acce-6ba1-401c-bf2a-027c227c4db7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b8f3830a3e43bdadef4f1de300203c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='The markets were bullish after news of the merger', description='Headline:',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classify(text: str) -> dict:\n",
    "    \"\"\"Classify a headline and print the results\"\"\"\n",
    "    return predictor.predict({\"inputs\":[text]})[0]\n",
    "\n",
    "\n",
    "# Either try out the interactive widget:\n",
    "interaction = widgets.interact_manual(\n",
    "    classify,\n",
    "    text=widgets.Text(\n",
    "        value=\"The markets were bullish after news of the merger\",\n",
    "        placeholder=\"Type a news headline...\",\n",
    "        description=\"Headline:\",\n",
    "        layout=widgets.Layout(width=\"99%\"),\n",
    "    ),\n",
    ")\n",
    "interaction.widget.children[1].description = \"Classify!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1d76f-4a2e-41ab-b498-e3b8c1611e9d",
   "metadata": {},
   "source": [
    "또는 (예를 들어 UI 위젯 라이브러리로 어려움을 겪고 있는 경우) 코드에서 직접 엔드포인트를 호출할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d11b0acb-f5b9-48b5-b7b3-404ad8158175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'Business', 'score': 0.9943668246269226}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"Retailers are expanding after the recent economic growth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebdcac-2f7c-43c6-8af0-a595960c9d07",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "세이지메이커 작업(예: 훈련, 처리 및 배치 추론)은 실행하는 동안에만 온디맨드 컴퓨팅을 사용하지만, 배포된 실시간 추론 엔드포인트는 해제할 때까지 리소스를 계속 소비한다는 점에 유의하세요.\n",
    "\n",
    "실험이 끝나면 더 이상 필요하지 않은 엔드포인트를 삭제하여 불필요한 비용을 피하세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b2cec-d728-4b90-ba01-98b5bd5c0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ba7286-50b7-45e7-9a4c-db5d1ba96bcc",
   "metadata": {},
   "source": [
    "## 리뷰\n",
    "\n",
    "이 노트북에서는 Amazon SageMaker에서 허깅 페이스 트랜스포머를 사용해 텍스트 분류 모델을 훈련하고 배포하는 방법을 보여드렸습니다.\n",
    "\n",
    "이 접근법의 몇 가지 이점은 함께 제공되는 [Headline Classifier Local notebook](Headline%20Classifier%20Local.ipynb)과 비교했을 때 다음과 같습니다:\n",
    "\n",
    "- **훈련 작업 기간 동안만** 전문 컴퓨팅 리소스(예: 고성능 또는 GPU 가속 인스턴스)를 자동으로 프로비저닝할 수 있습니다: 활용도가 낮은 리소스를 방치하지 않고 트레이닝에서 우수한 성능을 얻을 수 있습니다.\n",
    "- 사용자가 무엇이 효과가 있고 무엇이 효과가 없었는지를 기록해야 하는 로컬 노트북 실험과 달리, 훈련 작업의 이력(매개변수, 메트릭, 아웃풋 등)이 자동으로 추적됩니다.\n",
    "- 학습된 모델은 단 한 번의 SDK 호출로 프로덕션에 바로 사용할 수 있는 안전한 웹 엔드포인트에 배포할 수 있습니다: 동작을 심층적으로 사용자 정의하려는 경우가 아니라면 컨테이너나 웹 애플리케이션 패키징이 필요하지 않습니다.\n",
    "\n",
    "로컬 노트북과 이 SageMaker 버전 및 함께 제공되는 [scripts/train.py](스크립트/트레인.py) 스크립트 파일을 비교하면 자체 또는 오픈 소스 노트북 내 ML 워크플로를 SageMaker \"스크립트 모드\" 훈련 작업으로 마이그레이션하는 방법에 대한 아이디어를 얻을 수 있습니다.\n",
    "\n",
    "이 워크샵의 다음 '마이그레이션 챌린지' 연습에서는 다른 '로컬' 노트북에 대해 이 과정을 직접 반복해 보겠습니다.\n",
    "\n",
    "또한 SageMaker 작업을 파이프라인으로 연결하고 CI/CD로 워크플로우를 자동화하는 등의 추가 단계를 보여주는 [aws-samples/amazon-sagemaker-from-idea-to-production](https://github.com/aws-samples/amazon-sagemaker-from-idea-to-production)에도 관심이 있을 경우 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7943dfb0-6987-4144-8f87-5f9e4b9f6ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
