{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1c08a9-6046-41da-baf5-9c9ea48f5fdd",
   "metadata": {},
   "source": [
    "# ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ë¶„ë¥˜í•˜ê¸° (SageMaker ë²„ì „)\n",
    "\n",
    "> ì´ ë…¸íŠ¸ë¶ì€ ì„¸ì´ì§€ë©”ì´ì»¤ ìŠ¤íŠœë””ì˜¤ì˜ `Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)` ì»¤ë„ì—ì„œ ì˜ ì‘ë™í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì˜ˆì œì—ì„œëŠ” ì‚¬ìš©ì ì •ì˜ ìŠ¤í¬ë¦½íŠ¸ì™€ [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ë¶„ë¥˜ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ \"SageMaker\" ë…¸íŠ¸ë¶ì—ì„œëŠ” Amazon SageMaker í›ˆë ¨ ì‘ì—…ì—ì„œ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³ , ë§¤ë‹ˆì§€ë“œ ì‹¤ì‹œê°„ ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ë¡œ ë°°í¬í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.\n",
    "\n",
    "> âš ï¸ ì—¬ê¸°ì„œëŠ” ì—¬ê¸° ë…¸íŠ¸ë¶ ìì²´ì—ì„œ í›ˆë ¨ ë° ì¶”ë¡ ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì£¼ëŠ”, ë™ë°˜ëœ [\"Headline Classifier Local\" notebook](Headline%20Classifier%20Local.ipynb)ì„ ì´ë¯¸ ì‹¤í–‰í•œ ê²ƒìœ¼ë¡œ ê°€ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57514090-30b2-46c3-bee6-cb013b2038cb",
   "metadata": {},
   "source": [
    "## ì„¤ì¹˜ ë° ì„¤ì •\n",
    "\n",
    "ë¡œì»¬ ë…¸íŠ¸ë¶ì—ì„œì™€ ë§ˆì°¬ê°€ì§€ë¡œ, ì‹œì‘í•˜ê¸° ì „ì— ìœ„ì ¯ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ğŸŸ¢ í•˜ì§€ë§Œ **ë¡œì»¬ ë…¸íŠ¸ë¶ê³¼ ë‹¬ë¦¬** HF Transformersë¥¼ **ì„¤ì¹˜í•  í•„ìš”ê°€ ì—†ë‹¤**ëŠ” ì ì— ìœ ì˜í•˜ì„¸ìš”: ì‹¤ì œ í›ˆë ¨ê³¼ ì¶”ë¡ ì€ ì´ ì»¤ë„ì´ ì•„ë‹Œ ì»¨í…Œì´ë„ˆí™”ëœ ì‘ì—…ì—ì„œ ì´ë£¨ì–´ì§€ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "> â„¹ï¸ (ì‹¤ì œë¡œ ë™ì¼í•œ ì»¤ë„ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì—¬ëŸ¬ ê°œì˜ ì„¸ì´ì§€ë©”ì´ì»¤ ìŠ¤íŠœë””ì˜¤ ë…¸íŠ¸ë¶ì„ ì‹œì‘í•˜ë©´ í™˜ê²½ì„ ê³µìœ í•˜ê²Œ ë©ë‹ˆë‹¤: ë”°ë¼ì„œ ë¡œì»¬ ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ê³  ë™ì¼í•œ ì»¤ë„ì„ ì„ íƒí–ˆë‹¤ê³  ê°€ì •í•˜ë©´ ëª¨ë“  ê²ƒì´ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2cc7de2-59b4-49a7-8823-6953e2531cea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets<8 in /opt/conda/lib/python3.9/site-packages (7.7.5)\n",
      "Requirement already satisfied: sagemaker<3,>2.140 in /opt/conda/lib/python3.9/site-packages (2.143.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (1.1.4)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.4 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (3.6.4)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (5.5.6)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (0.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (8.10.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (5.9.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (1.23.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (0.3.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (4.17.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (1.5.3)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (4.13.0)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (5.4.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (0.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.28 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (1.26.70)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (3.2.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (23.0)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (22.2.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (0.1.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (3.20.2)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.9/site-packages (from sagemaker<3,>2.140) (0.7.5)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker<3,>2.140) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.70 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker<3,>2.140) (1.29.70)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from boto3<2.0,>=1.26.28->sagemaker<3,>2.140) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker<3,>2.140) (3.13.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8) (6.2)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8) (8.1.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (2.14.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (5.1.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.6.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (3.0.36)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.18.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker<3,>2.140) (1.16.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.9/site-packages (from widgetsnbextension~=3.6.4->ipywidgets<8) (6.5.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema->sagemaker<3,>2.140) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->sagemaker<3,>2.140) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->sagemaker<3,>2.140) (2022.7.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker<3,>2.140) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker<3,>2.140) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker<3,>2.140) (0.70.14)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.9/site-packages (from pathos->sagemaker<3,>2.140) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.9/site-packages (from schema->sagemaker<3,>2.140) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.70->boto3<2.0,>=1.26.28->sagemaker<3,>2.140) (1.26.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8) (0.8.3)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (21.3.0)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (5.8.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.16.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (7.2.10)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (24.0.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (3.1.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (5.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.5.6)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.17.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.5.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=4.0.0->ipywidgets<8) (0.2.6)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (2.2.1)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.9/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.5.0)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.2.2)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (6.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (4.12.0)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.0.5)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.7.1)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.2.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.5.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.2.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.1.2)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.9/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.16.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (21.2.0)\n",
      "Requirement already satisfied: jupyter-events>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.6.3)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (3.6.2)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.5.1)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.4.4)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.9/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.4)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.9/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.5.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.21)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.9/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.0.7)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.1.1)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.9/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.1.4)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.9/site-packages (from jsonschema->sagemaker<3,>2.140) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.9/site-packages (from jsonschema->sagemaker<3,>2.140) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.9/site-packages (from jsonschema->sagemaker<3,>2.140) (2.3)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.9/site-packages (from jsonschema->sagemaker<3,>2.140) (1.13)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.9/site-packages (from jsonschema->sagemaker<3,>2.140) (1.2.0)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from isoduration->jsonschema->sagemaker<3,>2.140) (1.2.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"ipywidgets<8\" \"sagemaker>2.140,<3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e5d2d-d062-468f-96dc-d51018cc2450",
   "metadata": {},
   "source": [
    "ì„¤ì¹˜ê°€ ì™„ë£Œë˜ë©´ ë‚˜ë¨¸ì§€ ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©í•  ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ Python ë‚´ì¥ ê¸°ëŠ¥ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "\n",
    "[%autoreload magic](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html)ì€ ë¡œì»¬ .py íŒŒì¼ë¡œ ì‘ì—…í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤. ì…€ì„ ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ë©´ ë…¸íŠ¸ë¶ ì»¤ë„ì„ ì¬ì‹œì‘í•  í•„ìš” ì—†ì´ ë¡œì»¬ì—ì„œ í¸ì§‘/ì—…ë°ì´íŠ¸ëœ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ğŸŸ¢ ì´ë²ˆì—ëŠ” ë¡œì»¬ ë…¸íŠ¸ë¶ì—ì„œëŠ” í•„ìš” ì—†ë˜ **AWS libraries**ë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤:\n",
    "\n",
    "- `boto3`, [general-purpose AWS SDK for Python](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)\n",
    "- `sagemaker`,[high-level Python SDK for Amazon SageMaker](https://sagemaker.readthedocs.io/en/stable/)\n",
    "\n",
    "ì´ ë‘ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ëª¨ë‘ ì˜¤í”ˆì†ŒìŠ¤ì´ë©°, PyPIì™€ GitHubì— ê²Œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efbe751a-dce5-4dd1-b96c-35738d28fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import os  # Operating system utils e.g. file paths\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3  # General AWS SDK for Python\n",
    "import ipywidgets as widgets  # Interactive prediction widget\n",
    "import pandas as pd  # Utilities for working with data tables (dataframes)\n",
    "import sagemaker  # High-level Python SDK for Amazon SageMaker\n",
    "\n",
    "local_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b6e3e-1f50-4337-8339-fc05d71af52f",
   "metadata": {},
   "source": [
    "## ë°ì´í„°ì…‹ ì¤€ë¹„ ë° ì—…ë¡œë“œí•˜ê¸°\n",
    "\n",
    "ì´ ì˜ˆì—ì„œëŠ” [Registry of Open Data on AWS](https://registry.opendata.aws/fast-ai-nlp/)ì˜ í¼ë¸”ë¦­ ë¦¬í¬ì§€í† ë¦¬ì—ì„œ **FastAi AG News** ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì—ëŠ” ë‰´ìŠ¤ í—¤ë“œë¼ì¸ê³¼ ê·¸ì— í•´ë‹¹í•˜ëŠ” í† í”½ í´ë˜ìŠ¤ì˜ í…Œì´ë¸”ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131a0145-9033-4112-a67f-5e229679229e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://fast-ai-nlp/ag_news_csv.tgz to data/ag_news_csv.tgz\n",
      "Done!\n",
      "CPU times: user 64 ms, sys: 22.5 ms, total: 86.4 ms\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download the AG News data from the Registry of Open Data on AWS.\n",
    "!mkdir -p {local_dir}\n",
    "!aws s3 cp s3://fast-ai-nlp/ag_news_csv.tgz {local_dir} --no-sign-request\n",
    "\n",
    "# Un-tar the AG News data.\n",
    "!tar zxf {local_dir}/ag_news_csv.tgz -C {local_dir}/ --strip-components=1 --no-same-owner\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba225c-14bd-4941-8fa0-a68fe7f5fe6f",
   "metadata": {},
   "source": [
    "ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì¶”ì¶œí•œ í›„ ì•„ë˜ì™€ ê°™ì´ ëª‡ ê°€ì§€ ì˜ˆë¥¼ ì‚´í´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5369b9a2-c6f8-46ce-9b98-9451817be488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86110</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>Oracle to drop PeopleSoft suit if tender fails</td>\n",
       "      <td>Oracle Corp. notified Delaware's Court of Chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74390</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>NTT DoCoMo, IBM, Intel team to secure mobile d...</td>\n",
       "      <td>With an eye towards making mobile devices and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77491</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>Election Is Crunch Time for U.S. Secret Service</td>\n",
       "      <td>With just days to go before the U.S. president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27497</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Former Celtic striker Larsson on Barcelona bench</td>\n",
       "      <td>Henrik Larsson was left on the bench by Barcel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47492</th>\n",
       "      <td>World</td>\n",
       "      <td>Four Suicides Linked to Child Porn Probe (AP)</td>\n",
       "      <td>AP - The government will press on with a child...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CATEGORY                                              TITLE  \\\n",
       "86110  Sci/Tech     Oracle to drop PeopleSoft suit if tender fails   \n",
       "74390  Sci/Tech  NTT DoCoMo, IBM, Intel team to secure mobile d...   \n",
       "77491  Sci/Tech    Election Is Crunch Time for U.S. Secret Service   \n",
       "27497    Sports   Former Celtic striker Larsson on Barcelona bench   \n",
       "47492     World      Four Suicides Linked to Child Porn Probe (AP)   \n",
       "\n",
       "                                                 CONTENT  \n",
       "86110  Oracle Corp. notified Delaware's Court of Chan...  \n",
       "74390  With an eye towards making mobile devices and ...  \n",
       "77491  With just days to go before the U.S. president...  \n",
       "27497  Henrik Larsson was left on the bench by Barcel...  \n",
       "47492  AP - The government will press on with a child...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"CATEGORY\", \"TITLE\", \"CONTENT\"]\n",
    "# we use the train.csv only\n",
    "df = pd.read_csv(f\"{local_dir}/train.csv\", names=column_names, header=None, delimiter=\",\")\n",
    "# shuffle the DataFrame rows\n",
    "df = df.sample(frac=1, random_state=1337)\n",
    "\n",
    "# Make the (1-indexed) category classes more readable:\n",
    "class_names = [\"Other\", \"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "idx2label = {ix: name for ix, name in enumerate(class_names)}\n",
    "label2idx = {name: ix for ix, name in enumerate(class_names)}\n",
    "\n",
    "df = df.replace({\"CATEGORY\": idx2label})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f56818-09f1-48fc-bd5b-21530e7ef9c5",
   "metadata": {},
   "source": [
    "ì´ë²ˆ ì—°ìŠµì—ì„œëŠ” **ì•„ë˜ì˜ ê°’ë§Œ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤**:\n",
    "\n",
    "- ë‰´ìŠ¤ ê¸°ì‚¬ì˜ **title** (Headline)ì„ ì¸í’‹ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- ì˜ˆì¸¡í•  ëª©í‘œ ë³€ìˆ˜ë¡œ **category**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë°ì´í„° ì„¸íŠ¸ì—ëŠ” ì•„ë˜ì™€ ê°™ì´ 4ê°œì˜ ê· ë“±í•˜ê²Œ ë¶„í¬ëœ ì£¼ì œ í´ë˜ìŠ¤ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "> â„¹ï¸ **'Other'ëŠ” ì–´ë–»ê²Œ í• ê¹Œìš”?:** ì›ì‹œ ë°ì´í„° ì„¸íŠ¸ëŠ” 1~4 ì‚¬ì´ì˜ ìˆ«ìë¡œ ë²”ì£¼ë¥¼ ë‚˜íƒ€ë‚´ë©°, ìš°ë¦¬ì˜ ëª¨ë¸ì€ 0ë¶€í„° ì‹œì‘í•˜ëŠ” ìˆ«ìë¥¼ ì˜ˆìƒí•˜ê¸° ë•Œë¬¸ì—, ë°ì´í„° ì¤€ë¹„ë¥¼ ë‹¨ìˆœí•˜ê²Œ ìœ ì§€í•˜ê³  í´ë˜ìŠ¤ì˜ í˜¼ë€ìŠ¤ëŸ¬ìš´ ì¶”ê°€ ìˆ«ì í‘œí˜„ì„ í”¼í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” 'Other' í´ë˜ìŠ¤ë¥¼ ì‚½ì…í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a70b377-ee49-4780-8b32-57db4ee149ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sci/Tech    30000\n",
       "Sports      30000\n",
       "World       30000\n",
       "Business    30000\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CATEGORY\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db84ebf-e768-4d32-ad34-fc627cfe9597",
   "metadata": {},
   "source": [
    "ì§€ê¸ˆê¹Œì§€ ìƒˆë¡œìš´ ê²ƒì€ ì—†ìŠµë‹ˆë‹¤...\n",
    "\n",
    "ğŸŸ¢ ì„¸ì´ì§€ë©”ì´ì»¤ í›ˆë ¨ì˜ ì£¼ìš” ì°¨ì´ì ì€ [í›ˆë ¨ ì‘ì—…ì—ì„œ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆëŠ” ê³³ì—](https://docs.aws.amazon.com/sagemaker/latest/dg/model-access-training-data.html) ë°ì´í„°ì…‹ì„ **ì—…ë¡œë“œ**í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” [SageMaker default bucket](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-ex-bucket.html)ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ [Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html)ì— ì—…ë¡œë“œí•˜ê² ìŠµë‹ˆë‹¤. ì›í•˜ëŠ” ê²½ìš° ë²„í‚·ê³¼ í´ë” ì ‘ë‘ì‚¬ë¥¼ ì‚¬ìš©ì ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ê°™ì€ í´ë”ì— ë‘ íŒŒì¼ë§Œ ì €ì¥í•˜ì§€ ë§ê³  ë³„ë„ì˜ S3 í´ë”ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec896d2-e210-4987-aac5-d21d968816cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_s3_uri: s3://sagemaker-us-east-1-603420654815/sm101/news/train\n",
      "test_s3_uri: s3://sagemaker-us-east-1-603420654815/sm101/news/test\n"
     ]
    }
   ],
   "source": [
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "s3_prefix = \"sm101/news\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "s3.Bucket(bucket_name).upload_file(f\"{local_dir}/train.csv\", f\"{s3_prefix}/train/train.csv\")\n",
    "train_s3_uri = f\"s3://{bucket_name}/{s3_prefix}/train\"\n",
    "print(f\"train_s3_uri: {train_s3_uri}\")\n",
    "\n",
    "s3.Bucket(bucket_name).upload_file(f\"{local_dir}/test.csv\", f\"{s3_prefix}/test/test.csv\")\n",
    "test_s3_uri = f\"s3://{bucket_name}/{s3_prefix}/test\"\n",
    "print(f\"test_s3_uri: {test_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628acab-0b0b-4b77-9800-8dc154c55249",
   "metadata": {
    "tags": []
   },
   "source": [
    "## í›ˆë ¨ ë§¤ê°œë³€ìˆ˜ ì •ì˜\n",
    "\n",
    "[Hugging Face Hub](https://huggingface.co/models)ì—ì„œ (ë¹„êµì  ì‘ì€) ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ê³ , ë‚®ì€ ìˆ˜ì¤€ì˜ í›ˆë ¨ ë£¨í”„ë¥¼ ì²˜ìŒë¶€í„° ì‘ì„±í•˜ëŠ” ëŒ€ì‹  ë†’ì€ ìˆ˜ì¤€ì˜ [Trainer API](https://huggingface.co/docs/transformers/main_classes/trainer)ë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ğŸŸ¢ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ëŠ” ê¶ê·¹ì ìœ¼ë¡œ ì´ì „ê³¼ ë¹„ìŠ·í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ ì´ë²ˆì—ëŠ” **í›ˆë ¨ ì‘ì—… API**ë¥¼ í†µí•´ ì „ë‹¬í•  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸° ë…¸íŠ¸ë¶ì—ì„œ **JSON ì§ë ¬í™” ê°€ëŠ¥ ë§¤ê°œë³€ìˆ˜**ë¥¼ ì •ì˜í•œ ë‹¤ìŒ, ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚˜ì¤‘ì— `transformers.TrainingArguments`ë¥¼ ë¹Œë“œí•  ê²ƒì…ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21191118-ecc3-4b42-bf84-76882582ce31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'amazon/bort',\n",
       " 'class_names': 'Other,World,Sports,Business,Sci/Tech',\n",
       " 'num_train_epochs': 3,\n",
       " 'per_device_train_batch_size': 32,\n",
       " 'per_device_eval_batch_size': 64,\n",
       " 'warmup_steps': 500}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"model_id\": \"amazon/bort\",  # ID of the pre-trained model to start from\n",
    "    \"class_names\": \",\".join(class_names),  # Comma-separated list of category names\n",
    "    \"num_train_epochs\": 3,  # This time, we'll actually train for a full 3 epochs\n",
    "    \"per_device_train_batch_size\": 32,  # Note this is higher than we could set on local hardware\n",
    "    \"per_device_eval_batch_size\": 64,  # Note this is higher than we could set on local hardware\n",
    "    \"warmup_steps\": 500,  # Higher than we could set with the reduced local training\n",
    "}\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a37d97-07f7-4985-8b6a-19aa751d1ab4",
   "metadata": {},
   "source": [
    "# ë©”íŠ¸ë¦­ ì •ì˜\n",
    "\n",
    "í•™ìŠµëœ ëª¨ë¸ì˜ í’ˆì§ˆì„ ì¸¡ì •í•˜ëŠ” ë°©ë²•ì„ ì •ì˜í•˜ê³  ì´ ì •ë³´ë¥¼ ì„¸ì´ì§€ë©”ì´ì»¤ì— í‘œì‹œí•˜ì—¬ ë©”íŠ¸ë¦­ ë¡œê¹…, ìë™ ëª¨ë¸ íŠœë‹ ë° ë¦¬ë”ë³´ë“œì™€ ê°™ì€ ê¸°ëŠ¥ì„ í™œì„±í™”í•˜ê³ ì í•©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸŸ¢ í‰ì†Œì™€ ê°™ì´ í›ˆë ¨ ì½”ë“œê°€ ë©”íŠ¸ë¦­ì„ í”„ë¦°íŠ¸í•˜ë„ë¡ í•˜ê³ , [use regular expressions](https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html#define-train-metrics)ì„ í†µí•´ ì„¸ì´ì§€ë©”ì´ì»¤ê°€ ì‘ì—… ë¡œê·¸ì—ì„œ êµ¬ì¡°í™”ëœ ë©”íŠ¸ë¦­ì„ ìŠ¤í¬ë©í•˜ëŠ” ë°©ë²•ì„ ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "935497f0-1b44-450e-a725-8b65509231a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Name': 'Epoch', 'Regex': \"'epoch': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Train:Loss', 'Regex': \"'loss': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Train:LearningRate', 'Regex': \"'learning_rate': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Loss', 'Regex': \"'eval_loss': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Accuracy', 'Regex': \"'eval_accuracy': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:F1', 'Regex': \"'eval_f1': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Precision',\n",
       "  'Regex': \"'eval_precision': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Recall', 'Regex': \"'eval_recall': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:Runtime', 'Regex': \"'eval_runtime': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:SamplesPerSecond',\n",
       "  'Regex': \"'eval_samples_per_second': ([0-9\\\\.\\\\-e]+)\"},\n",
       " {'Name': 'Validation:StepsPerSecond',\n",
       "  'Regex': \"'eval_steps_per_second': ([0-9\\\\.\\\\-e]+)\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_definitions = [\n",
    "    {\"Name\": \"Epoch\", \"Regex\": r\"'epoch': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Train:Loss\", \"Regex\": r\"'loss': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Train:LearningRate\", \"Regex\": r\"'learning_rate': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Loss\", \"Regex\": r\"'eval_loss': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Accuracy\", \"Regex\": r\"'eval_accuracy': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:F1\", \"Regex\": r\"'eval_f1': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Precision\", \"Regex\": r\"'eval_precision': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Recall\", \"Regex\": r\"'eval_recall': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:Runtime\", \"Regex\": r\"'eval_runtime': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:SamplesPerSecond\", \"Regex\": r\"'eval_samples_per_second': ([0-9\\.\\-e]+)\"},\n",
    "    {\"Name\": \"Validation:StepsPerSecond\", \"Regex\": r\"'eval_steps_per_second': ([0-9\\.\\-e]+)\"},\n",
    "]\n",
    "metric_definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2df25-93e0-4f15-89de-844b291d6862",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ì„¸ì´ì§€ë©”ì´ì»¤ì—ì„œ ëª¨ë¸ í›ˆë ¨ ë° ê²€ì¦í•˜ê¸°\n",
    "\n",
    "ì´ë²ˆì—ëŠ” ë…¸íŠ¸ë¶ ìì²´ì™€ ë³„ë„ì˜ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•´ [SageMaker training job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html)ì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤: ì´ë¥¼ í†µí•´ ìˆ˜ëª…ì´ ê¸´ ë…¸íŠ¸ë¶ í™˜ê²½ê³¼ ë…ë¦½ì ìœ¼ë¡œ ì„ì‹œ í›ˆë ¨ ì¸í”„ë¼ì˜ í¬ê¸°ë¥¼ ì ì ˆíˆ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ğŸŸ¢ ë…¸íŠ¸ë¶ì—ì„œ ì‹¤ì œ í›ˆë ¨ ì½”ë“œë¥¼ **[scripts/train.py](scripts/train.py)**ì— íŒ©í„°ë§í–ˆìœ¼ë©°, ì´ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ë°°í¬í•˜ê¸° ìœ„í•´ ë¯¸ë¦¬ ë¹Œë“œëœ [ì„¸ì´ì§€ë©”ì´ì»¤ íŒŒì´ì¬ SDKë¥¼ í†µí•œ í—ˆê¹… í˜ì´ìŠ¤ í”„ë ˆì„ì›Œí¬ ì»¨í…Œì´ë„ˆ](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html)ë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70294b2-ee08-4c90-a7f7-d88ed52e07cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Amazon SageMakerê°€ ì‚¬ì „ ë¹Œë“œëœ ì»¨í…Œì´ë„ˆë¡œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰ì‹œí‚¤ëŠ” ë°©ë²• \n",
    "\n",
    "AWSëŠ” ì£¼ìš” ë¨¸ì‹ ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ì—ì„œ í”„ë¡œì íŠ¸ë¥¼ ë¹ ë¥´ê²Œ êµ¬ì¶•í•  ìˆ˜ ìˆë„ë¡ ì‚¬ì „ íŒ¨í‚¤ì§€ëœ Docker ì´ë¯¸ì§€ ì„¸íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤:[SageMaker Framework Containers](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers-prebuilt.html).\n",
    "\n",
    "ì´ ì»¨í…Œì´ë„ˆëŠ” GPU ë“œë¼ì´ë²„, ì„œë¹™ ìŠ¤íƒ êµ¬í˜„, í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë“±ê³¼ ê°™ì€ ê¸°ë³¸ ì„¤ì •ì„ ì²˜ë¦¬í•˜ë¯€ë¡œ í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ ë° ì¶”ë¡  ë™ì‘ ì˜¤ë²„ë¼ì´ë“œë¥¼ ìœ„í•œ Python ìŠ¤í¬ë¦½íŠ¸ë§Œ ê°„ë‹¨íˆ ì‚½ì…í•˜ë©´ ë©ë‹ˆë‹¤. ì‹¬ì§€ì–´ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì— ë¹Œë“œí•  í•„ìš” ì—†ì´ ì‹œì‘ ì‹œ ë™ì ìœ¼ë¡œ ì„¤ì¹˜í•  ì¶”ê°€ ì¢…ì†ì„±ì„ ì§€ì •í•˜ëŠ” *requirements.txt* íŒŒì¼ì„ ì œê³µí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ë”°ë¼ì„œ ì²« ë²ˆì§¸ ì‘ì—…ì€ ìŠ¤í¬ë¦½íŠ¸ì™€ ëŸ°íƒ€ì„ ê°„ì˜ ì¸í„°í˜ì´ìŠ¤**ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤: ìŠ¤í¬ë¦½íŠ¸ê°€ ì…ë ¥ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ì½ì„ ê²ƒì¸ê°€? ë§¤ê°œë³€ìˆ˜ëŠ”? ê²°ê³¼ë¥¼ ì–´ë””ì— ì €ì¥í•´ì•¼ í• ê¹Œìš”?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a6b41-a844-42e2-b3a7-d07252a394f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### í›ˆë ¨ ì¤‘ì¸ ì»¨í…Œì´ë„ˆ\n",
    "\n",
    "í›ˆë ¨ ì‘ì—… ì»¨í…Œì´ë„ˆê°€ ì‹œì‘ë˜ë©´ **ì½”ë“œ ë° ì¸í’‹ ë°ì´í„°**ê°€ `/opt/ml` ë””ë ‰í„°ë¦¬ ì•„ë˜ì˜ **ë¡œì»¬ íŒŒì¼**ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤. ë˜í•œ ì•„ë˜ì™€ ê°™ì´ í•™ìŠµëœ ëª¨ë¸ê³¼ ê¸°íƒ€ íŒŒì¼ ì¶œë ¥ì„ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì— ì €ì¥í•©ë‹ˆë‹¤:\n",
    "\n",
    "\n",
    "```\n",
    "    /opt/ml\n",
    "    |-- code\n",
    "    |   `-- <our script(s)>\n",
    "    |-- input\n",
    "    |   |-- config\n",
    "    |   |   |-- hyperparameters.json\n",
    "    |   |   `-- resourceConfig.json\n",
    "    |   `-- data\n",
    "    |       `-- <channel_name>\n",
    "    |           `-- <input data>\n",
    "    |-- model\n",
    "    |   `-- <model files>\n",
    "    `-- output\n",
    "        `-- failure\n",
    "```\n",
    "\n",
    "\n",
    "##### ì¸í’‹\n",
    "\n",
    "* `/opt/ml/input/config`ì—ëŠ” í”„ë¡œê·¸ë¨ ì‹¤í–‰ ë°©ì‹ì„ ì œì–´í•˜ëŠ” ì •ë³´ê°€ ë“¤ì–´ ìˆìŠµë‹ˆë‹¤. `hyperparameters.json`ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì´ë¦„ì„ ê°’ìœ¼ë¡œ ë³€í™˜í•œ JSON í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤. ì´ ê°’ì€ í•­ìƒ ë¬¸ìì—´ì´ë¯€ë¡œ ë³€í™˜í•´ì•¼ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. `resourceConfig.json`ì€ ë¶„ì‚° í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ë„¤íŠ¸ì›Œí¬ ë ˆì´ì•„ì›ƒì„ ì„¤ëª…í•˜ëŠ” JSON í˜•ì‹ì˜ íŒŒì¼ì…ë‹ˆë‹¤. scikit-learnì€ ë¶„ì‚° í•™ìŠµì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¬´ì‹œí•˜ê² ìŠµë‹ˆë‹¤.\n",
    "* (íŒŒì¼ ëª¨ë“œì˜ ê²½ìš°) `/opt/ml/input/data/<channel_name>/`ì—ëŠ” í•´ë‹¹ ì±„ë„ì˜ ì¸í’‹ ë°ì´í„°ê°€ í¬í•¨ë©ë‹ˆë‹¤. ì±„ë„ì€ CreateTrainingJob í˜¸ì¶œì— ë”°ë¼ ìƒì„±ë˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ì±„ë„ì´ ì•Œê³ ë¦¬ì¦˜ì´ ì˜ˆìƒí•˜ëŠ” ê²ƒê³¼ ì¼ì¹˜í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ê° ì±„ë„ì˜ íŒŒì¼ì€ S3 í‚¤ êµ¬ì¡°ë¡œ í‘œì‹œëœ íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ S3ì—ì„œ ì´ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬ë©ë‹ˆë‹¤. \n",
    "* (íŒŒì´í”„ ëª¨ë“œì˜ ê²½ìš°) `/opt/ml/input/data/<channel_name>_<epoch_number>`ëŠ” ì£¼ì–´ì§„ ì—í¬í¬ì— ëŒ€í•œ íŒŒì´í”„ì…ë‹ˆë‹¤. ì—í¬í¬ëŠ” 0ì—ì„œ ì‹œì‘í•˜ì—¬ ì½ì„ ë•Œë§ˆë‹¤ í•˜ë‚˜ì”© ì˜¬ë¼ê°‘ë‹ˆë‹¤. ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì—í¬í¬ ìˆ˜ì—ëŠ” ì œí•œì´ ì—†ì§€ë§Œ ë‹¤ìŒ ì—í¬í¬ë¥¼ ì½ê¸° ì „ì— ê° íŒŒì´í”„ë¥¼ ë‹«ì•„ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "##### ì•„ì›ƒí’‹\n",
    "\n",
    "* `/opt/ml/model/`ì€ ì•Œê³ ë¦¬ì¦˜ì´ ìƒì„±í•˜ëŠ” ëª¨ë¸ì„ ì‘ì„±í•˜ëŠ” ë””ë ‰í† ë¦¬ì…ë‹ˆë‹¤. ëª¨ë¸ì€ ì›í•˜ëŠ” ëª¨ë“  í˜•ì‹ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¨ì¼ íŒŒì¼ ë˜ëŠ” ì „ì²´ ë””ë ‰í† ë¦¬ íŠ¸ë¦¬ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” ì´ ë””ë ‰í† ë¦¬ì— ìˆëŠ” ëª¨ë“  íŒŒì¼ì„ ì••ì¶•ëœ íƒ€ë¥´ ì•„ì¹´ì´ë¸Œ íŒŒì¼ë¡œ íŒ¨í‚¤ì§•í•©ë‹ˆë‹¤. ì´ íŒŒì¼ì€ `DescribeTrainingJob` ê²°ê³¼ì—ì„œ ë°˜í™˜ëœ S3 ìœ„ì¹˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "* `/opt/ml/output`ì€ ì•Œê³ ë¦¬ì¦˜ì´ ì‘ì—…ì´ ì‹¤íŒ¨í•œ ì´ìœ ë¥¼ ì„¤ëª…í•˜ëŠ” `failure` íŒŒì¼ì„ ì‘ì„±í•  ìˆ˜ ìˆëŠ” ë””ë ‰í„°ë¦¬ì…ë‹ˆë‹¤. ì´ íŒŒì¼ì˜ ë‚´ìš©ì€ `DescribeTrainingJob` ê²°ê³¼ì˜ `FailureReason` í•„ë“œì— ë°˜í™˜ë©ë‹ˆë‹¤. ì„±ê³µí•œ ì‘ì—…ì˜ ê²½ìš° ë¬´ì‹œë˜ë¯€ë¡œ ì´ íŒŒì¼ì„ ì‘ì„±í•  ì´ìœ ê°€ ì—†ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591f290d-7eb9-4acf-b9d4-5df4a06e3f57",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ì¶”ê°€ ì •ë³´\n",
    "\n",
    "ìì„¸í•œ ë‚´ìš©ì€ ë‹¤ìŒì„ ì°¸ì¡°í•˜ì„¸ìš”:\n",
    "\n",
    "- [SageMaker Python SDK guide for Hugging Face](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html) ë° HF í”„ë ˆì„ì›Œí¬ í´ë˜ìŠ¤ì— ëŒ€í•œ [API doc](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”. (PyTorchì˜ í•´ë‹¹ í˜ì´ì§€ë„ ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤).\n",
    "- ê¸°ë³¸ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ì •ì˜í•˜ëŠ” GitHubì˜ [AWS Deep Learning Containers repository](https://github.com/aws/deep-learning-containers).\n",
    "- í›ˆë ¨ ë° ì„œë¹„ìŠ¤ë¥¼ ìœ„í•œ í”„ë ˆì„ì›Œí¬ ì½”ë“œì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ì˜¤í”ˆ ì†ŒìŠ¤ [SageMaker Training Toolkit](https://github.com/aws/sagemaker-training-toolkit) ë° [SageMaker Inference Toolkit](https://github.com/aws/sagemaker-inference-toolkit)ì„ ì°¸ì¡°í•˜ì„¸ìš”. (ì¼ë¶€ í”„ë ˆì„ì›Œí¬ëŠ” ì´ëŸ¬í•œ íˆ´í‚·ì˜ ë³€í˜•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì˜ˆ: [sagemaker-pytorch-training-toolkit](https://github.com/aws/sagemaker-pytorch-training-toolkit))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d648ba-8214-423e-926d-1417d56e413c",
   "metadata": {},
   "source": [
    "### ì‘ì—… ìƒì„±í•˜ê¸°\n",
    "\n",
    "ì‹¤ì œ [SageMaker CreateTrainingJob API](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html)ì—ëŠ” ì„¸ì´ì§€ë©”ì´ì»¤ íŒŒì´ì¬ SDKì˜ ìƒìœ„ [high-level 'Estimator' classes](https://sagemaker.readthedocs.io/en/stable/overview.html)ê°€ ë‹¨ìˆœí™”í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ëª‡ ê°€ì§€ í•˜ìœ„ ë ˆë²¨ ì„¸ë¶€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. íŠ¹íˆ:\n",
    "\n",
    "- ì •í™•í•œ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ URIë¥¼ ì§€ì •í•˜ëŠ” ëŒ€ì‹  ì„ íƒí•œ í”„ë ˆì„ì›Œí¬ ë° ë²„ì „ì— ë”°ë¼ SDKê°€ ì´ë¥¼ ì°¾ì•„ì¤ë‹ˆë‹¤.\n",
    "- SDKëŠ” `scripts` ë²ˆë“¤ì„ íˆ¬ëª…í•˜ê²Œ ì••ì¶•í•˜ì—¬ S3ì— ì—…ë¡œë“œí•˜ê³ , ê±°ê¸°ì—ì„œ ë¡œë“œí•˜ë„ë¡ í›ˆë ¨ ì‘ì—…ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì €, ì‘ì—…ì„ êµ¬ì„±í•˜ëŠ” `estimator` ê°ì²´ì™€ ì´ ì‘ì—…ì´ ì‹¤í–‰ë  ì¸í”„ë¼(ì»´í“¨íŒ… ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ì™€ ìœ í˜•)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:\n",
    "\n",
    "> â„¹ï¸ ì‚¬ìš©ìë¥¼ ëŒ€ì‹ í•˜ì—¬ ì‘ì—…ì„ ì‹¤í–‰í•˜ëŠ” ë‹¤ë¥¸ ì„œë¹„ìŠ¤ì™€ ë§ˆì°¬ê°€ì§€ë¡œ, í›ˆë ¨ ì‘ì—…ì€ [IAM ì—­í• ](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)ì„ ì„¤ì •í•˜ì—¬ S3ì˜ ì¸í’‹ í›ˆë ¨ ë°ì´í„°ì™€ ê°™ì€ ë¦¬ì†ŒìŠ¤ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì„¸ì´ì§€ë©”ì´ì»¤ ë…¸íŠ¸ë¶ ìì²´ëŠ” ì´ë¯¸ ê°€ì •ëœ ì—­í• ë¡œ ì‹¤í–‰ë˜ë¯€ë¡œ, ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ í›ˆë ¨ ì‘ì—… ì—­í• ì„ ë…¸íŠ¸ë¶ ì—­í• ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f6dbe0-6c13-4199-b219-5fe4e4543d03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.estimator import HuggingFace as HuggingFaceEstimator\n",
    "\n",
    "nb_role = sagemaker.get_execution_role()\n",
    "\n",
    "estimator = HuggingFaceEstimator(\n",
    "    transformers_version=\"4.26\",\n",
    "    pytorch_version=\"1.13\",\n",
    "    py_version=\"py39\",\n",
    "\n",
    "    source_dir=\"scripts\",  # Local folder where fine-tuning script is stored\n",
    "    entry_point=\"train.py\",  # Actual script the training job should run\n",
    "\n",
    "    base_job_name=\"news-classifier\",  # Prefix for the training job name (timestamp will be added)\n",
    "    instance_count=1,  # Number of instances train on (need to prepare your script for using >1!)\n",
    "    instance_type=\"ml.p3.2xlarge\",  # Type of compute instance to use: p* and g* include GPUs\n",
    "    role=nb_role,  # IAM role the job will use to access AWS resources (e.g. data on S3)\n",
    "\n",
    "    hyperparameters= hyperparameters,   # Training job parameters, as we set up earlier\n",
    "    metric_definitions=metric_definitions,  # RegEx to extract metric data from training job logs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c804ca-7678-4277-9f74-f3851d7efa5a",
   "metadata": {},
   "source": [
    "êµ¬ì„±ì´ ì™„ë£Œë˜ë©´ `estimator.fit()`ì„ ì‹¤í–‰í•˜ê³  ì¸í’‹ ë°ì´í„° ìœ„ì¹˜ë¥¼ ì§€ì •í•˜ì—¬ ì‹¤ì œ í›ˆë ¨ ì‘ì—…ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë°ì´í„° ì¸í’‹ 'ì±„ë„'ì˜ ìˆ˜, ì´ë¦„ ë° ìœ í˜•ì€ [ì‚¬ìš©ìì—ê²Œ ë‹¬ë ¤ ìˆìŠµë‹ˆë‹¤](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateTrainingJob.html#sagemaker-CreateTrainingJob-request-InputDataConfig): ë…¸íŠ¸ë¶ì´ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì˜ˆìƒí•˜ëŠ” ê²ƒê³¼ ë™ì¼í•œ ì±„ë„ì„ êµ¬ì„±í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f351c2e7-70ee-4d02-8b28-b1792073b8df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: news-classifier-2023-03-30-16-09-35-281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 16:09:37 Starting - Starting the training job...\n",
      "2023-03-30 16:10:02 Starting - Preparing the instances for training......\n",
      "2023-03-30 16:11:07 Downloading - Downloading input data...\n",
      "2023-03-30 16:11:27 Training - Downloading the training image..................\n",
      "2023-03-30 16:14:28 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,115 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,134 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,146 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,149 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,414 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,447 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,479 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:45,492 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"class_names\": \"Other,World,Sports,Business,Sci/Tech\",\n",
      "        \"model_id\": \"amazon/bort\",\n",
      "        \"num_train_epochs\": 3,\n",
      "        \"per_device_eval_batch_size\": 64,\n",
      "        \"per_device_train_batch_size\": 32,\n",
      "        \"warmup_steps\": 500\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"news-classifier-2023-03-30-16-09-35-281\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-603420654815/news-classifier-2023-03-30-16-09-35-281/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"class_names\":\"Other,World,Sports,Business,Sci/Tech\",\"model_id\":\"amazon/bort\",\"num_train_epochs\":3,\"per_device_eval_batch_size\":64,\"per_device_train_batch_size\":32,\"warmup_steps\":500}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-603420654815/news-classifier-2023-03-30-16-09-35-281/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"class_names\":\"Other,World,Sports,Business,Sci/Tech\",\"model_id\":\"amazon/bort\",\"num_train_epochs\":3,\"per_device_eval_batch_size\":64,\"per_device_train_batch_size\":32,\"warmup_steps\":500},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"news-classifier-2023-03-30-16-09-35-281\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-603420654815/news-classifier-2023-03-30-16-09-35-281/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--class_names\",\"Other,World,Sports,Business,Sci/Tech\",\"--model_id\",\"amazon/bort\",\"--num_train_epochs\",\"3\",\"--per_device_eval_batch_size\",\"64\",\"--per_device_train_batch_size\",\"32\",\"--warmup_steps\",\"500\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_CLASS_NAMES=Other,World,Sports,Business,Sci/Tech\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=amazon/bort\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_EVAL_BATCH_SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_STEPS=500\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 train.py --class_names Other,World,Sports,Business,Sci/Tech --model_id amazon/bort --num_train_epochs 3 --per_device_eval_batch_size 64 --per_device_train_batch_size 32 --warmup_steps 500\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:14:47.624: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:47,631 root         INFO     Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:14:47,661 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)okenizer_config.json:   0%|          | 0.00/1.04k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04k/1.04k [00:00<00:00, 129kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)lve/main/config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 507/507 [00:00<00:00, 90.3kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)olve/main/vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 899k/899k [00:00<00:00, 85.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)olve/main/merges.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 55.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)cial_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 772/772 [00:00<00:00, 298kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:   0%|          | 0.00/255M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:   4%|â–         | 10.5M/255M [00:00<00:06, 37.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:   8%|â–Š         | 21.0M/255M [00:01<00:14, 15.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  12%|â–ˆâ–        | 31.5M/255M [00:01<00:10, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  16%|â–ˆâ–‹        | 41.9M/255M [00:01<00:07, 29.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  21%|â–ˆâ–ˆ        | 52.4M/255M [00:01<00:05, 39.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  25%|â–ˆâ–ˆâ–       | 62.9M/255M [00:02<00:05, 37.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  29%|â–ˆâ–ˆâ–Š       | 73.4M/255M [00:02<00:05, 36.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  33%|â–ˆâ–ˆâ–ˆâ–      | 83.9M/255M [00:02<00:04, 34.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 94.4M/255M [00:03<00:04, 33.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 105M/255M [00:03<00:03, 40.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 115M/255M [00:03<00:04, 34.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 126M/255M [00:03<00:03, 41.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 136M/255M [00:04<00:03, 37.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 147M/255M [00:04<00:03, 33.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 157M/255M [00:04<00:02, 33.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 168M/255M [00:05<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 178M/255M [00:05<00:02, 34.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 189M/255M [00:05<00:01, 34.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 199M/255M [00:06<00:01, 30.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 210M/255M [00:06<00:01, 33.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 220M/255M [00:06<00:01, 31.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 231M/255M [00:07<00:00, 28.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 241M/255M [00:07<00:00, 28.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 252M/255M [00:07<00:00, 28.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (â€¦)\"pytorch_model.bin\";: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 255M/255M [00:07<00:00, 32.0MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at amazon/bort were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at amazon/bort and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at amazon/bort were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of BertForSequenceClassification were not initialized from the model checkpoint at amazon/bort and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:15:01,281 - datasets.builder - WARNING - Using custom data configuration default-b3addd5ffbf832ab\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-b3addd5ffbf832ab/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\u001b[0m\n",
      "\u001b[34mDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-b3addd5ffbf832ab/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:15:04,728 - __main__ - INFO - Loaded train_dataset length is: 120000\u001b[0m\n",
      "\u001b[34m2023-03-30 16:15:04,786 - datasets.builder - WARNING - Using custom data configuration default-74fbc9d322077d2a\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-74fbc9d322077d2a/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\u001b[0m\n",
      "\u001b[34mDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-74fbc9d322077d2a/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:15:05,089 - __main__ - INFO - Loaded test_dataset length is: 7600\u001b[0m\n",
      "\u001b[34mUsing cuda_amp half precision backend\u001b[0m\n",
      "\u001b[34mUsing cuda_amp half precision backend\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m***** Running training *****\u001b[0m\n",
      "\u001b[34mNum examples = 120000\n",
      "  Num Epochs = 3\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 120000\n",
      "  Num Epochs = 3\u001b[0m\n",
      "\u001b[34mInstantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11250\u001b[0m\n",
      "\u001b[34mInstantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11250\u001b[0m\n",
      "\u001b[34mNumber of trainable parameters = 76162053\u001b[0m\n",
      "\u001b[34mNumber of trainable parameters = 76162053\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.148: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.26.0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-03-30 16:15:07,154 - root - INFO - Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.189 algo-1:49 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.228 algo-1:49 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.228 algo-1:49 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.229 algo-1:49 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.230 algo-1:49 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-03-30 16:15:07.230 algo-1:49 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34mYou're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34mYou're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m{'loss': 1.3377, 'learning_rate': 5e-05, 'epoch': 0.13}\u001b[0m\n",
      "\u001b[34m{'loss': 0.7977, 'learning_rate': 4.7674418604651164e-05, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34m{'loss': 0.6202, 'learning_rate': 4.5348837209302326e-05, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5383, 'learning_rate': 4.302325581395349e-05, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m{'loss': 0.5191, 'learning_rate': 4.0697674418604655e-05, 'epoch': 0.67}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4978, 'learning_rate': 3.837209302325582e-05, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m{'loss': 0.4733, 'learning_rate': 3.604651162790698e-05, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\u001b[0m\n",
      "\u001b[34mBatch size = 64\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.44027823209762573, 'eval_accuracy': 0.8527631578947369, 'eval_f1': 0.8527631578947369, 'eval_precision': 0.8527631578947369, 'eval_recall': 0.8527631578947369, 'eval_runtime': 1.7576, 'eval_samples_per_second': 4324.056, 'eval_steps_per_second': 67.706, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-3750\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-3750\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-3750/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-3750/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-3750/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-3750/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-3750/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-3750/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-3750/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-3750/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.3862, 'learning_rate': 3.372093023255814e-05, 'epoch': 1.07}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3425, 'learning_rate': 3.13953488372093e-05, 'epoch': 1.2}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3366, 'learning_rate': 2.9069767441860467e-05, 'epoch': 1.33}\u001b[0m\n",
      "\u001b[34m{'loss': 0.33, 'learning_rate': 2.674418604651163e-05, 'epoch': 1.47}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3242, 'learning_rate': 2.441860465116279e-05, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3279, 'learning_rate': 2.2097674418604654e-05, 'epoch': 1.73}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3381, 'learning_rate': 1.9772093023255812e-05, 'epoch': 1.87}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3274, 'learning_rate': 1.7446511627906977e-05, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\u001b[0m\n",
      "\u001b[34mNum examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34mBatch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4255436062812805, 'eval_accuracy': 0.8586842105263158, 'eval_f1': 0.8586842105263158, 'eval_precision': 0.8586842105263158, 'eval_recall': 0.8586842105263158, 'eval_runtime': 1.7699, 'eval_samples_per_second': 4293.948, 'eval_steps_per_second': 67.234, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-7500\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-7500\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-7500/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-7500/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-7500/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-7500/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-7500/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-7500/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-7500/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-7500/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m{'loss': 0.2252, 'learning_rate': 1.5120930232558139e-05, 'epoch': 2.13}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2288, 'learning_rate': 1.2800000000000001e-05, 'epoch': 2.27}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2309, 'learning_rate': 1.0474418604651164e-05, 'epoch': 2.4}\u001b[0m\n",
      "\u001b[34m{'loss': 0.234, 'learning_rate': 8.148837209302326e-06, 'epoch': 2.53}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2204, 'learning_rate': 5.823255813953488e-06, 'epoch': 2.67}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2291, 'learning_rate': 3.502325581395349e-06, 'epoch': 2.8}\u001b[0m\n",
      "\u001b[34m{'loss': 0.2295, 'learning_rate': 1.1767441860465117e-06, 'epoch': 2.93}\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.44188404083251953, 'eval_accuracy': 0.861578947368421, 'eval_f1': 0.861578947368421, 'eval_precision': 0.861578947368421, 'eval_recall': 0.861578947368421, 'eval_runtime': 1.6449, 'eval_samples_per_second': 4620.359, 'eval_steps_per_second': 72.345, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-11250\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /tmp/transformers/checkpoints/checkpoint-11250\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-11250/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /tmp/transformers/checkpoints/checkpoint-11250/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-11250/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /tmp/transformers/checkpoints/checkpoint-11250/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-11250/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /tmp/transformers/checkpoints/checkpoint-11250/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-11250/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /tmp/transformers/checkpoints/checkpoint-11250/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from /tmp/transformers/checkpoints/checkpoint-11250 (score: 0.861578947368421).\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34mLoading best model from /tmp/transformers/checkpoints/checkpoint-11250 (score: 0.861578947368421).\u001b[0m\n",
      "\u001b[34m{'train_runtime': 426.9917, 'train_samples_per_second': 843.108, 'train_steps_per_second': 26.347, 'train_loss': 0.408696252102322, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34mNum examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 7600\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.44188404083251953, 'eval_accuracy': 0.861578947368421, 'eval_f1': 0.861578947368421, 'eval_precision': 0.861578947368421, 'eval_recall': 0.861578947368421, 'eval_runtime': 1.64, 'eval_samples_per_second': 4634.054, 'eval_steps_per_second': 72.56, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m***** Eval results *****\u001b[0m\n",
      "\u001b[34m2023-03-30 16:22:16,931 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:22:16,931 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-03-30 16:22:16,931 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-03-30 16:22:21 Uploading - Uploading generated training model\n",
      "2023-03-30 16:23:32 Completed - Training job completed\n",
      "Training seconds: 745\n",
      "Billable seconds: 745\n",
      "CPU times: user 4.93 s, sys: 191 ms, total: 5.13 s\n",
      "Wall time: 14min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimator.fit(\n",
    "    {\n",
    "        \"train\": train_s3_uri,\n",
    "        \"test\": test_s3_uri,\n",
    "    },\n",
    "    wait=True,  # Wait for the training to complete (default=True)\n",
    "    logs=True,  # Stream training job logs to the notebook (default=True, requires wait=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c940a-77cc-472e-8263-fe2a0c236f9b",
   "metadata": {},
   "source": [
    "> â° ì´ í›ˆë ¨ ì‘ì—…ì€ ì™„ë£Œí•˜ëŠ” ë° 10ë¶„ ì •ë„ ê±¸ë¦¬ì§€ë§Œ 'ë¡œì»¬' ëª¨ë¸ë³´ë‹¤ í›¨ì”¬ ë” ë†’ì€ ì •í™•ë„ì— ë„ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "íŠ¸ë ˆì´ë‹ ìì²´ëŠ” ì†Œí˜• CPU ì „ìš© ë…¸íŠ¸ë¶ì´ ì•„ë‹Œ GPU ê°€ì† ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ ì´ì „ì˜ 'ë¡œì»¬' ì˜ˆì œë³´ë‹¤ í›¨ì”¬ ë¹¨ë¼ì•¼ í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì¸í”„ë¼ë¥¼ í”„ë¡œë¹„ì €ë‹í•˜ê³  ì‘ì—…ì„ ì‹œì‘í•˜ëŠ” ë°ëŠ” ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "[ì•„ë§ˆì¡´ ì„¸ì´ì§€ë©”ì´ì»¤ìš© AWS Console](https://console.aws.amazon.com/sagemaker/home?#/jobs)ì˜ *Training jobs* í˜ì´ì§€ì™€ ì„¸ì´ì§€ë©”ì´ì»¤ ìŠ¤íŠœë””ì˜¤ì˜ **Experiments** UI(ì™¼ìª½ ì‚¬ì´ë“œë°”ì˜ ğŸ  **í™ˆ** ë²„íŠ¼ì—ì„œ)ì—ì„œë„ í˜„ì¬ ë° ê³¼ê±° ì‘ì—…ì˜ ìƒíƒœë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ğŸŸ¢ ëŒ€ê¸° ë° ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°ì˜ ê¸°ë³¸ ë™ì‘ì€ ë¡œì»¬ê³¼ ìœ ì‚¬í•œ ê²½í—˜ì„ ì œê³µí•˜ì§€ë§Œ, í›ˆë ¨ ì‘ì—…ì€ ë…¸íŠ¸ë¶ì— ì˜ì¡´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤:\n",
    "\n",
    "- ë…¸íŠ¸ë¶ì˜ ì—°ê²°ì„ ëŠê±°ë‚˜ ì¢…ë£Œí•´ë„ í›ˆë ¨ ì‘ì—…ì€ ê³„ì† ì§„í–‰ë©ë‹ˆë‹¤.\n",
    "- `wait=False`ë¥¼ ì„¤ì •í•˜ë©´ ë…¸íŠ¸ë¶ì—ì„œ ì—¬ëŸ¬ ê°œì˜ íŠ¸ë ˆì´ë‹ ì‘ì—…ì„ ë™ì‹œì— ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ì¬ì‹œì‘í•œ ë…¸íŠ¸ë¶ì„ ì´ì „ í›ˆë ¨ ì‘ì—…ì— ì—°ê²°í•´ì•¼ í•˜ëŠ” ê²½ìš°, ì•„ë˜ì™€ ê°™ì´ í›ˆë ¨ ì‘ì—… ì´ë¦„ìœ¼ë¡œ `.attach()`í•˜ë©´ ë©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6156d24-b630-4df3-a912-18cf1ed002f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-03-30 16:23:32 Starting - Preparing the instances for training\n",
      "2023-03-30 16:23:32 Downloading - Downloading input data\n",
      "2023-03-30 16:23:32 Training - Training image download completed. Training in progress.\n",
      "2023-03-30 16:23:32 Uploading - Uploading generated training model\n",
      "2023-03-30 16:23:32 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "# estimator = HuggingFaceEstimator.attach(\"news-classifier-2023-03-30-16-09-35-281\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf511626-84a6-4579-9a77-39d0fc048cc9",
   "metadata": {},
   "source": [
    "í›ˆë ¨ ì‘ì—…ì´ ì™„ë£Œë˜ë©´ ì»¨í…Œì´ë„ˆì˜ ëª¨ë¸ ì•„ì›ƒí’‹ í´ë”ì˜ ë‚´ìš©ì´ ìë™ìœ¼ë¡œ S3ì— ì•„ì¹´ì´ë¸Œë©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ ì´ íŒŒì¼ì„ ì°¸ì¡°í•  ìˆ˜ ìˆìœ¼ë©°, SageMaker ì™¸ë¶€ì—ì„œ í•™ìŠµëœ ëª¨ë¸ì„ ìœ ì‚¬í•œ íƒ€ë¥´ë³¼ í˜•ì‹ìœ¼ë¡œ ì¤€ë¹„í•˜ì—¬ ë°°í¬ìš©ìœ¼ë¡œ ê°€ì ¸ì˜¬ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c490cab6-7ae5-450d-b7ae-ff8156e5817d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-603420654815/news-classifier-2023-03-30-16-09-35-281/output/model.tar.gz'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.latest_training_job.describe()[\"ModelArtifacts\"][\"S3ModelArtifacts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2150a348-e0c3-40c7-9d5e-14c8c6986033",
   "metadata": {},
   "source": [
    "## ì¶”ë¡ ì— ëª¨ë¸ ì‚¬ìš©\n",
    "\n",
    "ëª¨ë¸ì´ í•™ìŠµë˜ë©´ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì¶”ë¡ ì— ì‚¬ìš©í•  ì¤€ë¹„ê°€ ëœ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì„¸ì´ì§€ë©”ì´ì»¤ëŠ” [ì˜¨ë””ë§¨ë“œ ì¶”ë¡ ì„ ìœ„í•œ ëª¨ë¸ ë°°í¬](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html) ë˜ëŠ” [ë°°ì¹˜ ì¶”ë¡  ì‘ì—… ì‹¤í–‰](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)ì„ ìœ„í•œ ì—¬ëŸ¬ ê°€ì§€ ì™„ì „ ê´€ë¦¬í˜• ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "> â„¹ï¸ **ì£¼ì˜ì‚¬í•­:** ì‚¬ìš© ì‚¬ë¡€ì— ì í•©í•œ ì¶”ë¡  ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš” - ë°°ì¹˜ ë°ì´í„°ë§Œ ì²˜ë¦¬í•˜ë ¤ëŠ” ê²½ìš° ì‹¤ì‹œê°„ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë°°í¬í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤!\n",
    ">\n",
    "> ì§€ê¸ˆê¹Œì§€ ì‚¬ìš©í–ˆë˜ ê²ƒê³¼ ë™ì¼í•œ ë†’ì€ ìˆ˜ì¤€ì˜ SageMaker Python SDKë¥¼ í†µí•´ ë°°ì¹˜ ì¶”ë¡ ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [SageMaker ë°°ì¹˜ ë³€í™˜ ì‚¬ìš©](https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-batch-transform)ì„ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.\n",
    "\n",
    "ì´ ì˜ˆì œì—ì„œëŠ” ëª¨ë¸ì„ [ì‹¤ì‹œê°„ ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)ì— ë°°í¬í•˜ì—¬ ì˜¨ë””ë§¨ë“œ ë°©ì‹ìœ¼ë¡œ í—¤ë“œë¼ì¸ì„ ë¶„ë¥˜í•  ìˆ˜ ìˆë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‹¤í–‰í•  ì¸í”„ë¼ ìœ í˜•ì„ ë‹¤ì‹œ ì§€ì •í•˜ë¯€ë¡œ ì‹œì‘í•˜ëŠ” ë° ëª‡ ë¶„ ì •ë„ ê±¸ë¦½ë‹ˆë‹¤. ì´ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸ëŠ” íŠ¸ë˜í”½ì„ ë§¤ìš° ì ê²Œ ì²˜ë¦¬í•˜ë¯€ë¡œ ë” ì‘ê³  ì €ë ´í•œ ì¸í”„ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ í›ˆë ¨ìš©ê³¼ëŠ” ë‹¤ë¥¸ ìœ í˜•ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "795f1525-b0f1-449a-9c17-e3b587e77a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: news-classifier-2023-03-30-16-33-41-922\n",
      "INFO:sagemaker:Creating endpoint-config with name news-classifier-2023-03-30-16-33-41-922\n",
      "INFO:sagemaker:Creating endpoint with name news-classifier-2023-03-30-16-33-41-922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7322a7f0-e2c1-45ec-9a96-eb64036c8384",
   "metadata": {},
   "source": [
    "ë°°í¬ í›„ì—ëŠ” [Amazon SageMakerìš© AWS ì½˜ì†”](https://console.aws.amazon.com/sagemaker/home?#/endpoints)ì˜ *Endpoints* í˜ì´ì§€ì™€ ì„¸ì´ì§€ë©”ì´ì»¤ ìŠ¤íŠœë””ì˜¤ UIì˜ **Deployments > Endpoints** ì„¹ì…˜(ì™¼ìª½ ì‚¬ì´ë“œë°”ì˜ ğŸ  **Home** ë²„íŠ¼ì—ì„œ)ì—ì„œ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "í›ˆë ¨ ì‘ì—…ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì—”ë“œí¬ì¸íŠ¸ëŠ” ë…¸íŠ¸ë¶ ìì²´ì—ì„œ ë¶„ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ì´ì „ì— ë°°í¬ëœ ì—”ë“œí¬ì¸íŠ¸ì— ë…¸íŠ¸ë¶ì„ ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371515a-ed8a-41a2-87f8-3fdf63dcfb9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sagemaker.huggingface import HuggingFacePredictor\n",
    "# predictor = HuggingFacePredictor(\"news-classifier-2023-03-24-13-31-09-895\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e58b2-f792-46e1-b7a3-7613bb9f3184",
   "metadata": {},
   "source": [
    "### ì´ì œ ëª¨ë¸ì´ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ RESTful APIë¡œ ì‘ë™í•©ë‹ˆë‹¤!\n",
    "\n",
    "[Predictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html)ëŠ” ì—¬ê¸°ì„œ ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ì§€ ì•Šê³  ëŒ€ì‹  ë°°í¬ëœ ì—”ë“œí¬ì¸íŠ¸ì— ëŒ€í•œ HTTPS API í˜¸ì¶œì„ ë˜í•‘í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” Hugging Face í”„ë ˆì„ì›Œí¬ì—ì„œ ì œê³µí•˜ëŠ” ê¸°ë³¸ `application/json` ì§ë ¬í™” ì§€ì›ì„ ì‚¬ìš©í•˜ê³  ìˆì§€ë§Œ, í”„ë ˆì„ì›Œí¬ë§ˆë‹¤ ê¸°ë³¸ í˜•ì‹ì´ ë‹¤ë¥´ë¯€ë¡œ ì‚¬ìš©ì ì •ì˜ [serializers](https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html) ë° [deserializers](https://sagemaker.readthedocs.io/en/stable/api/inference/deserializers.html)(client/`predictor` ì¸¡)ì™€ ì‚¬ìš©ì ì •ì˜ [`input_fn`s and `output_fn`s](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#process-model-input)(ì—”ë“œí¬ì¸íŠ¸ ì»¨í…Œì´ë„ˆ ì¸¡)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›í•˜ëŠ” ê±°ì˜ ëª¨ë“  ìš”ì²­ ë˜ëŠ” ì‘ë‹µ í˜•ì‹ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: ìì²´ ì„œë¹™ ìŠ¤íƒì„ ì²˜ìŒë¶€í„° ì‘ì„±í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìš”ì²­ ì—­/ì§ë ¬í™” ë° ì²˜ë¦¬ëŠ” ì´ë¯¸ [HuggingFacePredictor](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html#hugging-face-predictor)ì™€ ì‚¬ì „ êµ¬ì¶•ëœ ì¶”ë¡  ì»¨í…Œì´ë„ˆì— ì˜í•´ ì²˜ë¦¬ë˜ë¯€ë¡œ, ë…¸íŠ¸ë¶ì—ì„œ ë°°í¬ëœ ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” ê²ƒì€ ë¡œì»¬ ì¸ë©”ëª¨ë¦¬ ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” ê²ƒë§Œí¼ì´ë‚˜ ì‰½ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d658acce-6ba1-401c-bf2a-027c227c4db7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b8f3830a3e43bdadef4f1de300203c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='The markets were bullish after news of the merger', description='Headline:',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classify(text: str) -> dict:\n",
    "    \"\"\"Classify a headline and print the results\"\"\"\n",
    "    return predictor.predict({\"inputs\":[text]})[0]\n",
    "\n",
    "\n",
    "# Either try out the interactive widget:\n",
    "interaction = widgets.interact_manual(\n",
    "    classify,\n",
    "    text=widgets.Text(\n",
    "        value=\"The markets were bullish after news of the merger\",\n",
    "        placeholder=\"Type a news headline...\",\n",
    "        description=\"Headline:\",\n",
    "        layout=widgets.Layout(width=\"99%\"),\n",
    "    ),\n",
    ")\n",
    "interaction.widget.children[1].description = \"Classify!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1d76f-4a2e-41ab-b498-e3b8c1611e9d",
   "metadata": {},
   "source": [
    "ë˜ëŠ” (ì˜ˆë¥¼ ë“¤ì–´ UI ìœ„ì ¯ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆëŠ” ê²½ìš°) ì½”ë“œì—ì„œ ì§ì ‘ ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d11b0acb-f5b9-48b5-b7b3-404ad8158175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'Business', 'score': 0.9943668246269226}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"Retailers are expanding after the recent economic growth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebdcac-2f7c-43c6-8af0-a595960c9d07",
   "metadata": {},
   "source": [
    "## ì •ë¦¬\n",
    "\n",
    "ì„¸ì´ì§€ë©”ì´ì»¤ ì‘ì—…(ì˜ˆ: í›ˆë ¨, ì²˜ë¦¬ ë° ë°°ì¹˜ ì¶”ë¡ )ì€ ì‹¤í–‰í•˜ëŠ” ë™ì•ˆì—ë§Œ ì˜¨ë””ë§¨ë“œ ì»´í“¨íŒ…ì„ ì‚¬ìš©í•˜ì§€ë§Œ, ë°°í¬ëœ ì‹¤ì‹œê°„ ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸ëŠ” í•´ì œí•  ë•Œê¹Œì§€ ë¦¬ì†ŒìŠ¤ë¥¼ ê³„ì† ì†Œë¹„í•œë‹¤ëŠ” ì ì— ìœ ì˜í•˜ì„¸ìš”.\n",
    "\n",
    "ì‹¤í—˜ì´ ëë‚˜ë©´ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•Šì€ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚­ì œí•˜ì—¬ ë¶ˆí•„ìš”í•œ ë¹„ìš©ì„ í”¼í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b2cec-d728-4b90-ba01-98b5bd5c0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ba7286-50b7-45e7-9a4c-db5d1ba96bcc",
   "metadata": {},
   "source": [
    "## ë¦¬ë·°\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” Amazon SageMakerì—ì„œ í—ˆê¹… í˜ì´ìŠ¤ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ë°°í¬í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë ¸ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì ‘ê·¼ë²•ì˜ ëª‡ ê°€ì§€ ì´ì ì€ í•¨ê»˜ ì œê³µë˜ëŠ” [Headline Classifier Local notebook](Headline%20Classifier%20Local.ipynb)ê³¼ ë¹„êµí–ˆì„ ë•Œ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "- **í›ˆë ¨ ì‘ì—… ê¸°ê°„ ë™ì•ˆë§Œ** ì „ë¬¸ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤(ì˜ˆ: ê³ ì„±ëŠ¥ ë˜ëŠ” GPU ê°€ì† ì¸ìŠ¤í„´ìŠ¤)ë¥¼ ìë™ìœ¼ë¡œ í”„ë¡œë¹„ì €ë‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: í™œìš©ë„ê°€ ë‚®ì€ ë¦¬ì†ŒìŠ¤ë¥¼ ë°©ì¹˜í•˜ì§€ ì•Šê³  íŠ¸ë ˆì´ë‹ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ì‚¬ìš©ìê°€ ë¬´ì—‡ì´ íš¨ê³¼ê°€ ìˆê³  ë¬´ì—‡ì´ íš¨ê³¼ê°€ ì—†ì—ˆëŠ”ì§€ë¥¼ ê¸°ë¡í•´ì•¼ í•˜ëŠ” ë¡œì»¬ ë…¸íŠ¸ë¶ ì‹¤í—˜ê³¼ ë‹¬ë¦¬, í›ˆë ¨ ì‘ì—…ì˜ ì´ë ¥(ë§¤ê°œë³€ìˆ˜, ë©”íŠ¸ë¦­, ì•„ì›ƒí’‹ ë“±)ì´ ìë™ìœ¼ë¡œ ì¶”ì ë©ë‹ˆë‹¤.\n",
    "- í•™ìŠµëœ ëª¨ë¸ì€ ë‹¨ í•œ ë²ˆì˜ SDK í˜¸ì¶œë¡œ í”„ë¡œë•ì…˜ì— ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì•ˆì „í•œ ì›¹ ì—”ë“œí¬ì¸íŠ¸ì— ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: ë™ì‘ì„ ì‹¬ì¸µì ìœ¼ë¡œ ì‚¬ìš©ì ì •ì˜í•˜ë ¤ëŠ” ê²½ìš°ê°€ ì•„ë‹ˆë¼ë©´ ì»¨í…Œì´ë„ˆë‚˜ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ íŒ¨í‚¤ì§•ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë¡œì»¬ ë…¸íŠ¸ë¶ê³¼ ì´ SageMaker ë²„ì „ ë° í•¨ê»˜ ì œê³µë˜ëŠ” [scripts/train.py](ìŠ¤í¬ë¦½íŠ¸/íŠ¸ë ˆì¸.py) ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ë¹„êµí•˜ë©´ ìì²´ ë˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ë…¸íŠ¸ë¶ ë‚´ ML ì›Œí¬í”Œë¡œë¥¼ SageMaker \"ìŠ¤í¬ë¦½íŠ¸ ëª¨ë“œ\" í›ˆë ¨ ì‘ì—…ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì•„ì´ë””ì–´ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì›Œí¬ìƒµì˜ ë‹¤ìŒ 'ë§ˆì´ê·¸ë ˆì´ì…˜ ì±Œë¦°ì§€' ì—°ìŠµì—ì„œëŠ” ë‹¤ë¥¸ 'ë¡œì»¬' ë…¸íŠ¸ë¶ì— ëŒ€í•´ ì´ ê³¼ì •ì„ ì§ì ‘ ë°˜ë³µí•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë˜í•œ SageMaker ì‘ì—…ì„ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì—°ê²°í•˜ê³  CI/CDë¡œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìë™í™”í•˜ëŠ” ë“±ì˜ ì¶”ê°€ ë‹¨ê³„ë¥¼ ë³´ì—¬ì£¼ëŠ” [aws-samples/amazon-sagemaker-from-idea-to-production](https://github.com/aws-samples/amazon-sagemaker-from-idea-to-production)ì—ë„ ê´€ì‹¬ì´ ìˆì„ ê²½ìš° ì°¸ê³ í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7943dfb0-6987-4144-8f87-5f9e4b9f6ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
