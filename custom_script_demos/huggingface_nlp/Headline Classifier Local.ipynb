{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1c08a9-6046-41da-baf5-9c9ea48f5fdd",
   "metadata": {},
   "source": [
    "# ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ë¶„ë¥˜í•˜ê¸° (ë¡œì»¬ ë²„ì „)\n",
    "\n",
    "> ì´ ë…¸íŠ¸ë¶ì€ ì„¸ì´ì§€ë©”ì´ì»¤ ìŠ¤íŠœë””ì˜¤ ìƒì—ì„œ`Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)` ì»¤ë„ì„ ì‚¬ìš©í•˜ì§€ë©´ ì˜ ì‘ë™í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ì˜ˆì—ì„œëŠ” ì‚¬ìš©ì ì§€ì • ìŠ¤í¬ë¦½íŠ¸ì™€ [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ë¶„ë¥˜ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ \"ë¡œì»¬\" ë…¸íŠ¸ë¶ì€ ì—¬ê¸° ë…¸íŠ¸ë¶ ìì²´ì—ì„œ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°ëª¨ë¥¼ ë³´ì—¬ì¤„ ê²ƒì´ë©°, ë™ë°˜ë˜ëŠ” [\"SageMaker\" ë…¸íŠ¸ë¶](Headline%20Classifier%20SageMaker.ipynb)ì€ ì»¨í…Œì´ë„ˆí™”ëœ SageMaker í›ˆë ¨ ì‘ì—…ê³¼ ì—”ë“œí¬ì¸íŠ¸ ë°°í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì¼í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ë°˜ë³µí•  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "í—ˆê¹… í˜ì´ìŠ¤ë¥¼ ì²˜ìŒ ì‚¬ìš©í•˜ëŠ” ê²½ìš° [Transformers quick tour](https://huggingface.co/docs/transformers/quicktour)ë¥¼ ì½ì–´ë³´ê±°ë‚˜ ë‹¤ìŒ ì†Œê°œ ë™ì˜ìƒ(1ì‹œê°„)ì„ ì‹œì²­í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373d72c-7f09-4a87-851d-dc603412912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pYqjCzoyWyo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57514090-30b2-46c3-bee6-cb013b2038cb",
   "metadata": {},
   "source": [
    "## ì„¤ì¹˜ ë° ì„¤ì •\n",
    "\n",
    "ìœ„ì— ëª…ì‹œëœ íŒŒì´í† ì¹˜ ì„¸ì´ì§€ë©”ì´ì»¤ ì»¤ë„ì—ëŠ” í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ëŒ€ë¶€ë¶„ í¬í•¨ë˜ì–´ ìˆì§€ë§Œ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í¬í•¨ë˜ì–´ ìˆì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € ì ì ˆí•œ ë²„ì „ì˜ HF transformers/datasetsì„ ì„¤ì¹˜í•´ì•¼ í•˜ë©°, ë‚˜ì¤‘ì— ëŒ€í™”í˜• ë¶„ë¥˜ ìœ„ì ¯ì„ êµ¬ë™í•˜ê¸° ìœ„í•´ IPyWidgetsë„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "> âš ï¸ **Note:** ì´ ì…€ì„ ë¨¼ì € ì‹¤í–‰í•˜ëŠ” í•œ ë…¸íŠ¸ë¶ ì»¤ë„ì„ ì¬ì‹œì‘í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ë¯¸ ì–´ë–¤ ê²ƒì´ë¼ë„ 'import'ë¥¼ í•œ ê²½ìš°, ìœ„ì˜ ë„êµ¬ ëª¨ìŒì—ì„œ 'restart the kernel' ë²„íŠ¼ì„ í´ë¦­í•´ì•¼ ì„¤ì¹˜ê°€ ì ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ ì¶œë ¥ì—ì„œ pipì˜ *warnings*ëŠ” ë¬´ì‹œí•  ìˆ˜ ìˆì§€ë§Œ *errors*ëŠ” í‘œì‹œë˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc7de2-59b4-49a7-8823-6953e2531cea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install datasets \"ipywidgets<8\" transformers==4.26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e5d2d-d062-468f-96dc-d51018cc2450",
   "metadata": {},
   "source": [
    "ì„¤ì¹˜ê°€ ì™„ë£Œë˜ë©´ ë‚˜ë¨¸ì§€ ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©í•  ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ Python ë‚´ì¥ ê¸°ëŠ¥ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "\n",
    "[%autoreload magic](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html)ì€ ë¡œì»¬ .py íŒŒì¼ë¡œ ì‘ì—…í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤. ì…€ì„ ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ë©´ ë…¸íŠ¸ë¶ ì»¤ë„ì„ ì¬ì‹œì‘í•  í•„ìš” ì—†ì´ ë¡œì»¬ì—ì„œ í¸ì§‘/ì—…ë°ì´íŠ¸ëœ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe751a-dce5-4dd1-b96c-35738d28fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import os  # Operating system utils e.g. file paths\n",
    "\n",
    "# External Dependencies:\n",
    "import datasets  # Hugging Face data loading utilities\n",
    "import ipywidgets as widgets  # Interactive prediction widget\n",
    "import pandas as pd  # Utilities for working with data tables (dataframes)\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import transformers  # Hugging Face Transformers framework\n",
    "\n",
    "local_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b6e3e-1f50-4337-8339-fc05d71af52f",
   "metadata": {},
   "source": [
    "## ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "\n",
    "ì´ ì˜ˆì œì—ì„œëŠ” [Registry of Open Data on AWS](https://registry.opendata.aws/fast-ai-nlp/) í¼ë¸”ë¦­ ë¦¬í¬ì§€í† ë¦¬ì—ì„œ **FastAi AG News** ë°ì´í„° ì„¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. ì´ ë°ì´í„° ì„¸íŠ¸ì—ëŠ” ë‰´ìŠ¤ í—¤ë“œë¼ì¸ê³¼ ê·¸ì— í•´ë‹¹í•˜ëŠ” ì£¼ì œ í´ë˜ìŠ¤ì˜ í‘œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a0145-9033-4112-a67f-5e229679229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Download the AG News data from the Registry of Open Data on AWS.\n",
    "!mkdir -p {local_dir}\n",
    "!aws s3 cp s3://fast-ai-nlp/ag_news_csv.tgz {local_dir} --no-sign-request\n",
    "\n",
    "# Un-tar the AG News data.\n",
    "!tar zxf {local_dir}/ag_news_csv.tgz -C {local_dir}/ --strip-components=1 --no-same-owner\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba225c-14bd-4941-8fa0-a68fe7f5fe6f",
   "metadata": {},
   "source": [
    "ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì¶”ì¶œí•œ í›„ ì•„ë˜ì™€ ê°™ì´ ëª‡ ê°€ì§€ ì˜ˆë¥¼ ì‚´í´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369b9a2-c6f8-46ce-9b98-9451817be488",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"CATEGORY\", \"TITLE\", \"CONTENT\"]\n",
    "# we use the train.csv only\n",
    "df = pd.read_csv(f\"{local_dir}/train.csv\", names=column_names, header=None, delimiter=\",\")\n",
    "# shuffle the DataFrame rows\n",
    "df = df.sample(frac=1, random_state=1337)\n",
    "\n",
    "# Make the (1-indexed) category classes more readable:\n",
    "class_names = [\"Other\", \"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "idx2label = {ix: name for ix, name in enumerate(class_names)}\n",
    "label2idx = {name: ix for ix, name in enumerate(class_names)}\n",
    "\n",
    "df = df.replace({\"CATEGORY\": idx2label})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f56818-09f1-48fc-bd5b-21530e7ef9c5",
   "metadata": {},
   "source": [
    "ì´ë²ˆ ì—°ìŠµì—ì„œëŠ” **ì•„ë˜ì˜ ê°’ë§Œ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤**:\n",
    "\n",
    "- ë‰´ìŠ¤ ê¸°ì‚¬ì˜ **title**(Headline)ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- ì˜ˆì¸¡í•  ëª©í‘œ ë³€ìˆ˜ë¡œ **category**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë°ì´í„° ì„¸íŠ¸ì—ëŠ” ì•„ë˜ì™€ ê°™ì´ 4ê°œì˜ ê· ë“±í•˜ê²Œ ë¶„í¬ëœ í† í”½ í´ë˜ìŠ¤ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "> â„¹ï¸ **'Other'ëŠ” ì–´ë–»ê²Œ í• ê¹Œìš”?:** ì›ì‹œ ë°ì´í„° ì„¸íŠ¸ëŠ” 1~4 ì‚¬ì´ì˜ ìˆ«ìë¡œ ë²”ì£¼ë¥¼ ë‚˜íƒ€ë‚´ë©°, ìš°ë¦¬ì˜ ëª¨ë¸ì€ 0ë¶€í„° ì‹œì‘í•˜ëŠ” ìˆ«ìë¥¼ ì˜ˆìƒí•˜ê¸° ë•Œë¬¸ì—, ë°ì´í„° ì¤€ë¹„ë¥¼ ë‹¨ìˆœí•˜ê²Œ ìœ ì§€í•˜ê³  í´ë˜ìŠ¤ì˜ í˜¼ë€ìŠ¤ëŸ¬ìš´ ì¶”ê°€ ìˆ«ì í‘œí˜„ì„ í”¼í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” 'Other' í´ë˜ìŠ¤ë¥¼ ì‚½ì…í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70b377-ee49-4780-8b32-57db4ee149ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CATEGORY\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628acab-0b0b-4b77-9800-8dc154c55249",
   "metadata": {},
   "source": [
    "## í›ˆë ¨ íŒŒë¼ë¯¸í„° ì •ì˜\n",
    "\n",
    "[Hugging Face Hub](https://huggingface.co/models)ì—ì„œ (ë¹„êµì  ì‘ì€) ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ê³ , ë‚®ì€ ìˆ˜ì¤€ì˜ í•™ìŠµ ë£¨í”„ë¥¼ ì²˜ìŒë¶€í„° ì‘ì„±í•˜ëŠ” ëŒ€ì‹  ë†’ì€ ìˆ˜ì¤€ì˜ [Trainer API](https://huggingface.co/docs/transformers/main_classes/trainer)ë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ì—ì„œëŠ” í•™ìŠµì„ ìœ„í•œ ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "> ğŸï¸ ì´ ë…¸íŠ¸ë¶ ë‚´ ì˜ˆì œì—ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ **ì €ë ´í•œ CPU ì „ìš© ì»´í“¨íŒ…**ì„ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤. ìš°ë¦¬ê°€ í›ˆë ¨í•˜ëŠ” ëª¨ë¸ì€ ìµœì‹  LLM í‘œì¤€ì— ë”°ë¥´ë©´ \"ì†Œê·œëª¨\"ì´ì§€ë§Œ, í•©ë¦¬ì ì¸ ì‹œê°„ ë‚´ì— ì™„ë£Œí•  ìˆ˜ ìˆë„ë¡ í›ˆë ¨ì„ ë§¤ìš° ì¼ì° ì¤‘ë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    ">\n",
    "> ê²°ê³¼ ëª¨ë¸ì€ í•™ìŠµì´ ë§¤ìš° ë¶€ì¡±í•  ê²ƒì´ë©°, ë™ì¼í•œ ì•„í‚¤í…ì²˜ê°€ ê¶ê·¹ì ìœ¼ë¡œ ë„ë‹¬í•  ìˆ˜ ìˆëŠ” ê²ƒë³´ë‹¤ í›¨ì”¬ ëœ ì •í™•í•  ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c772a2-b9f1-4908-b7e0-07e162933fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"amazon/bort\"  # ID of the pre-trained model to start from\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=f\"{local_dir}/model\",  # Where to save trained model snapshots\n",
    "    #logging_dir=f\"{local_dir}/local-logs\",  # Optionally, save logs too\n",
    "    max_steps=500,  # Maximum number of training steps to run\n",
    "    num_train_epochs=3,  # Maximum number of times to loop through the training data\n",
    "    per_device_train_batch_size=16,  # Examples per mini-batch for training\n",
    "    per_device_eval_batch_size=32,  # Examples per mini-batch for validation\n",
    "    evaluation_strategy=\"steps\",  # Run validation every N 'steps' instead of every 'epoch'\n",
    "    eval_steps=100,  # Number of training steps between validation runs\n",
    "    save_strategy=\"steps\",  # Must be same as evaluation_strategy when load_best_model_at_end=True\n",
    "    load_best_model_at_end=True,  # If current model at end is not the best, load the best\n",
    "    metric_for_best_model=\"f1\",  # Use F1 score for judging which model is 'best'\n",
    "    learning_rate=5e-5,  # Initial learning rate (decays over time by default)\n",
    "    warmup_steps=100,  # Number of steps to gradually increase the learning rate from the start\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a37d97-07f7-4985-8b6a-19aa751d1ab4",
   "metadata": {},
   "source": [
    "## ë©”íŠ¸ë¦­ ì •ì˜\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” ëª¨ë¸ì´ ê²€ì¦ë  ë•Œë§ˆë‹¤ ì‹¤í–‰ë˜ëŠ” [callback function](https://huggingface.co/docs/transformers/main_classes/callback)ë¥¼ ì„¤ì •í•˜ì—¬ í•™ìŠµëœ ëª¨ë¸ì˜ í’ˆì§ˆì„ ì¸¡ì •í•˜ëŠ” ë°©ë²•ì„ ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca817667-2bb8-4098-9840-466d42a13d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"micro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2df25-93e0-4f15-89de-844b291d6862",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ í•™ìŠµ ë° ìœ íš¨ì„± ê²€ì‚¬\n",
    "\n",
    "ì´ ì„¹ì…˜ì—ì„œëŠ” ê¸°ë³¸ ëª¨ë¸ê³¼ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¡œë“œí•˜ê³  ì‹¤ì œ í›ˆë ¨ ë° ìœ íš¨ì„± ê²€ì‚¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì €, ì£¼ì–´ì§„ 'model_id'ì— ëŒ€í•´ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ê³¼ í•¨ê»˜ ì œê³µë˜ëŠ” [tokenizer](https://huggingface.co/docs/transformers/main_classes/tokenizer)ë¥¼ ë¡œë“œí•´ì•¼ í•˜ë©°, ì´ëŠ” í—ˆê¹… í˜ì´ìŠ¤ í—ˆë¸Œì—ì„œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë¸ì„ ì„¤ì •í•˜ëŠ” ê³¼ì •ì—ì„œ ë¯¸ì„¸ ì¡°ì •í•  í† í”½ í´ë˜ìŠ¤ì˜ ìˆ˜ë¥¼ ì§€ì •í•˜ê³  ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” ì´ë¦„ì„ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f351c2e7-70ee-4d02-8b28-b1792073b8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(class_names))\n",
    "model.config.label2id = label2idx\n",
    "model.config.id2label = idx2label\n",
    "\n",
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcabbc33-4f7a-4591-82d2-ec0b07bcb1d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "ë°ì´í„° ì„¸íŠ¸ì— ì´ë¯¸ ì œê³µëœ ì›ì‹œ `train.csv` ë° `test.csv` íŒŒì¼ì„ í›ˆë ¨ì˜ ì¸í’‹ìœ¼ë¡œ ì‚¬ìš©í•˜ê² ì§€ë§Œ, ë¨¼ì € ëª‡ ê°€ì§€ ì „ì²˜ë¦¬ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "- CSVì—ëŠ” ì—´ í—¤ë”ê°€ ì—†ìœ¼ë¯€ë¡œ, `column_names`ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- `tokenizer`ëŠ” ê¸´ í—¤ë“œë¼ì¸ì„ ëª¨ë¸ì´ ì§€ì›í•˜ëŠ” ìµœëŒ€ ê¸¸ì´ë¡œ ì˜ë¼ë‚´ëŠ” ê²ƒì„ í¬í•¨í•˜ì—¬ ì›ì‹œ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì´ ì˜ˆìƒí•˜ëŠ” (ìˆ«ì) ì¸í’‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610050f-63d8-43d1-9037-39e75d8bcf65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    \"\"\"Tokenize and pre-process raw examples for training/validation\"\"\"\n",
    "    result = tokenizer(batch[\"title\"], truncation=True)\n",
    "    result[\"label\"] = batch[\"category\"]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Load the raw datasets:\n",
    "raw_train_dataset = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=os.path.join(local_dir, \"train.csv\"),\n",
    "    column_names=[\"category\", \"title\", \"content\"],\n",
    "    split=datasets.Split.ALL,\n",
    ")\n",
    "raw_test_dataset = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=os.path.join(local_dir, \"test.csv\"),\n",
    "    column_names=[\"category\", \"title\", \"content\"],\n",
    "    split=datasets.Split.ALL,\n",
    ")\n",
    "\n",
    "# Run the tokenization/pre-processing, keeping only the output fields from preprocess()\n",
    "train_dataset = raw_train_dataset.map(\n",
    "    preprocess, batched=True, batch_size=1000, remove_columns=raw_train_dataset.column_names\n",
    ")\n",
    "test_dataset = raw_test_dataset.map(\n",
    "    preprocess, batched=True, batch_size=1000, remove_columns=raw_test_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427526e0-6fb6-45a0-94a0-9bb755a9f9e4",
   "metadata": {},
   "source": [
    "íŒŒë¼ë¯¸í„°ì™€ ì‚¬ì „ ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìœ¼ë¯€ë¡œ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  í‰ê°€í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "> â° **Note:** ê¸°ë³¸ `ml.t3.medium`(2 vCPU + 4 GiB RAM) Studio ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì—ì„œ ì´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì™„ë£Œí•˜ëŠ” ë° ì•½ 20ë¶„ì´ ì†Œìš”ë©ë‹ˆë‹¤.\n",
    ">\n",
    "> ê¸°ë‹¤ë¦¬ëŠ” ë™ì•ˆ [SageMaker notebook](Headline%20Classifier%20SageMaker.ipynb)ìœ¼ë¡œ ì´ë™í•˜ì—¬ ì´ í”„ë¡œì„¸ìŠ¤ê°€ SageMaker í›ˆë ¨ ì‘ì—…ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ë  ë•Œ ì–´ë–»ê²Œ ë‹¬ë¼ì§€ëŠ”ì§€ ì‚´í´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b077dc-5cb7-4945-885b-cfccd49c25d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# create Trainer instance\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer.train()\n",
    "\n",
    "# evaluate model\n",
    "eval_result = trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fd733-4aa9-457c-b369-a5cbcde46768",
   "metadata": {},
   "source": [
    "ë©”íŠ¸ë¦­ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ì—¬ê¸°ì—ì„œ í•™ìŠµëœ ëª¨ë¸ì€ ì •í™•ë„ê°€ ë†’ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë©°, í•™ìŠµì´ ì¢…ë£Œëœ ì‹œì ì—ì„œë„ ì •í™•ë„ê°€ ë¹ ë¥´ê²Œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e58b2-f792-46e1-b7a3-7613bb9f3184",
   "metadata": {},
   "source": [
    "## ì¶”ë¡ ì— ëª¨ë¸ ì‚¬ìš©\n",
    "\n",
    "ëª¨ë¸ì´ í•™ìŠµë˜ë©´ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì¶”ë¡ ì— ì‚¬ìš©í•  ì¤€ë¹„ê°€ ëœ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì—ì„œëŠ” í•™ìŠµ ê³¼ì •ì—ì„œ ëª¨ë¸ì´ ì´ë¯¸ ë©”ëª¨ë¦¬ì— ë¡œë“œë˜ì–´ ìˆìœ¼ë¯€ë¡œ [Pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines)ìœ¼ë¡œ ë˜í•‘í•˜ì—¬ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ ì…€ì€ ì‚¬ìš©ìê°€ ì§ì ‘ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì„ ì…ë ¥í•˜ê³  ëª¨ë¸ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ë¥˜í•˜ë„ë¡ í•  ìˆ˜ ìˆëŠ” ëŒ€í™”í˜• ìœ„ì ¯ì„ ìƒì„±í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658acce-6ba1-401c-bf2a-027c227c4db7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = transformers.pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "def classify(text: str) -> dict:\n",
    "    \"\"\"Classify a headline and print the results\"\"\"\n",
    "    print(pipe(text)[0])\n",
    "\n",
    "\n",
    "# Either try out the interactive widget:\n",
    "interaction = widgets.interact_manual(\n",
    "    classify,\n",
    "    text=widgets.Text(\n",
    "        value=\"The markets were bullish after news of the merger\",\n",
    "        placeholder=\"Type a news headline...\",\n",
    "        description=\"Headline:\",\n",
    "        layout=widgets.Layout(width=\"99%\"),\n",
    "    ),\n",
    ")\n",
    "interaction.widget.children[1].description = \"Classify!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1d76f-4a2e-41ab-b498-e3b8c1611e9d",
   "metadata": {},
   "source": [
    "ë˜ëŠ” ì½”ë“œì—ì„œ ì§ì ‘ íŒŒì´í”„ë¼ì¸ì„ í˜¸ì¶œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b0acb-f5b9-48b5-b7b3-404ad8158175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classify(\"Retailers are expanding after the recent economic growth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ba7286-50b7-45e7-9a4c-db5d1ba96bcc",
   "metadata": {},
   "source": [
    "## ë¦¬ë·°\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì¼ë°˜ Jupyter í™˜ê²½ì—ì„œ ë¡œì»¬ë¡œ í—ˆê¹… í˜ì´ìŠ¤ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë ¸ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê¸°ë³¸ ë…¸íŠ¸ë¶ ì»´í“¨íŒ… ì¸í”„ë¼(`ml.t3.medium`)ê°€ ìƒë‹¹íˆ ì‘ì•˜ê¸° ë•Œë¬¸ì— í›ˆë ¨ì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë ¸ê³  ê²°ê³¼ë¥¼ íƒìƒ‰í•´ ë³´ê¸° ìœ„í•´ ì¡°ê¸°ì— ì¤‘ë‹¨í•´ì•¼ í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- ë” ë‚˜ì€ ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ìœ„í•´ í›ˆë ¨ ì—í¬í¬/ë‹¨ê³„ ì»·ì˜¤í”„ë¥¼ í™•ì¥í•  ìˆ˜ ìˆì§€ë§Œ, ê·¸ëŸ¬ë©´ í”„ë¡œì„¸ìŠ¤ê°€ ë” ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.\n",
    "- ìŠ¤íŠœë””ì˜¤ ë…¸íŠ¸ë¶ì„ ë” ë†’ì€ ë¦¬ì†ŒìŠ¤ ì¸ìŠ¤í„´ìŠ¤(GPU ì‚¬ìš© ê°€ëŠ¥)ë¡œ ì „í™˜í•  ìˆ˜ë„ ìˆì§€ë§Œ, ê·¸ëŸ¬ë©´ ë°ì´í„° íƒìƒ‰ì´ë‚˜ í‰ê°€ ë“± ì‹¤ì œë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ì§€ ì•ŠëŠ” ì‹œê°„ì—ëŠ” ì¶”ê°€ ë¦¬ì†ŒìŠ¤ê°€ ìœ íœ´ ìƒíƒœê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ë˜í•œ í›ˆë ¨ ê³¼ì •ì—ì„œ ì‹œë„í•œ ë‹¤ì–‘í•œ ë§¤ê°œ ë³€ìˆ˜ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•´ ì‹¤í—˜ì„ ìˆ˜ë™ìœ¼ë¡œ ê¸°ë¡í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒìœ¼ë¡œ, [SageMaker notebook](Headline%20Classifier%20SageMaker.ipynb)ìœ¼ë¡œ ì´ë™í•˜ì—¬ í•„ìš”í•œ ë§Œí¼ë§Œ ë¹„ìš©ì„ ì§€ë¶ˆí•˜ë©´ì„œ ì˜¨ë””ë§¨ë“œ ì»´í“¨íŒ…ì„ í™œìš©í•˜ì—¬ ë” ë¹ ë¥¸ í›ˆë ¨ê³¼ ìë™ ë©”íƒ€ë°ì´í„° ì¶”ì ì„ ìˆ˜í–‰í•˜ëŠ” ë° SageMaker í›ˆë ¨ ì‘ì—… ë° ì—”ë“œí¬ì¸íŠ¸ ë°°í¬ë¥¼ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a359a-32fb-45df-9cad-c0cd4814e883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
