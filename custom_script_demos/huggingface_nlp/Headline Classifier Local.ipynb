{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1c08a9-6046-41da-baf5-9c9ea48f5fdd",
   "metadata": {},
   "source": [
    "# 뉴스 헤드라인 분류하기 (로컬 버전)\n",
    "\n",
    "> 이 노트북은 세이지메이커 스튜디오 상에서`Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)` 커널을 사용하지면 잘 작동합니다.\n",
    "\n",
    "이 예에서는 사용자 지정 스크립트와 [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) 프레임워크를 사용하여 뉴스 헤드라인 분류 모델을 훈련합니다.\n",
    "\n",
    "이 \"로컬\" 노트북은 여기 노트북 자체에서 모델을 훈련하고 테스트하는 데모를 보여줄 것이며, 동반되는 [\"SageMaker\" 노트북](Headline%20Classifier%20SageMaker.ipynb)은 컨테이너화된 SageMaker 훈련 작업과 엔드포인트 배포를 사용하여 동일한 프로세스를 반복할 것입니다.\n",
    "\n",
    "허깅 페이스를 처음 사용하는 경우 [Transformers quick tour](https://huggingface.co/docs/transformers/quicktour)를 읽어보거나 다음 소개 동영상(1시간)을 시청하는 것이 좋습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7373d72c-7f09-4a87-851d-dc603412912b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pYqjCzoyWyo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pYqjCzoyWyo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57514090-30b2-46c3-bee6-cb013b2038cb",
   "metadata": {},
   "source": [
    "## 설치 및 설정\n",
    "\n",
    "위에 명시된 파이토치 세이지메이커 커널에는 필요한 라이브러리가 대부분 포함되어 있지만 모든 라이브러리가 포함되어 있지는 않습니다. 먼저 적절한 버전의 HF transformers/datasets을 설치해야 하며, 나중에 대화형 분류 위젯을 구동하기 위해 IPyWidgets도 설치해야 합니다:\n",
    "\n",
    "> ⚠️ **Note:** 이 셀을 먼저 실행하는 한 노트북 커널을 재시작할 필요가 없습니다. 하지만 이미 어떤 것이라도 'import'를 한 경우, 위의 도구 모음에서 'restart the kernel' 버튼을 클릭해야 설치가 적용됩니다.\n",
    "\n",
    "아래 출력에서 pip의 *warnings*는 무시할 수 있지만 *errors*는 표시되지 않아야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2cc7de2-59b4-49a7-8823-6953e2531cea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.9/site-packages (2.11.0)\n",
      "Requirement already satisfied: ipywidgets<8 in /opt/conda/lib/python3.9/site-packages (7.7.5)\n",
      "Requirement already satisfied: transformers==4.26 in /opt/conda/lib/python3.9/site-packages (4.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26) (2023.3.23)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26) (0.13.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.26) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26) (4.64.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.26) (3.10.7)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26) (0.13.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.26) (5.4.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (5.5.6)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.4 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (3.6.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (5.9.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (0.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (8.10.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from ipywidgets<8) (1.1.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26) (4.4.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8) (6.2)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets<8) (8.1.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (3.0.36)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (2.14.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.18.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (5.1.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets<8) (0.6.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.26) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.26) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.26) (1.26.14)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.9/site-packages (from widgetsnbextension~=3.6.4->ipywidgets<8) (6.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8) (0.8.3)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.5.6)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (21.3.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (24.0.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (5.3.0)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (5.8.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.16.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.5.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (3.1.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.17.1)\n",
      "Requirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (7.2.10)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /opt/conda/lib/python3.9/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8) (4.13.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=4.0.0->ipywidgets<8) (0.2.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (1.2.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (0.2.2)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.9/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8) (2.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client->ipykernel>=4.5.1->ipywidgets<8) (3.13.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.9/site-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (3.2.0)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.9/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.5.0)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.2.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.7.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.1.2)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.0.5)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.7.1)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (6.0.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.2.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.2.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.9/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (4.12.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.9/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (4.17.3)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.9/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.16.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.19.3)\n",
      "Requirement already satisfied: jupyter-events>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.6.3)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.5.1)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.4.4)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (3.6.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.9/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.4)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.9/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.5.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.21)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.9/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.9/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.9/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (0.1.1)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.13)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.2.0)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (2.3)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.5.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.9/site-packages (from isoduration->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.4->ipywidgets<8) (1.2.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets \"ipywidgets<8\" transformers==4.26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e5d2d-d062-468f-96dc-d51018cc2450",
   "metadata": {},
   "source": [
    "설치가 완료되면 나머지 노트북에서 사용할 라이브러리와 Python 내장 기능을 로드합니다.\n",
    "\n",
    "[%autoreload magic](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html)은 로컬 .py 파일로 작업할 때 유용합니다. 셀을 실행할 때마다 라이브러리를 다시 로드하면 노트북 커널을 재시작할 필요 없이 로컬에서 편집/업데이트된 스크립트를 사용할 수 있기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efbe751a-dce5-4dd1-b96c-35738d28fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import os  # Operating system utils e.g. file paths\n",
    "\n",
    "# External Dependencies:\n",
    "import datasets  # Hugging Face data loading utilities\n",
    "import ipywidgets as widgets  # Interactive prediction widget\n",
    "import pandas as pd  # Utilities for working with data tables (dataframes)\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import transformers  # Hugging Face Transformers framework\n",
    "\n",
    "local_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b6e3e-1f50-4337-8339-fc05d71af52f",
   "metadata": {},
   "source": [
    "## 데이터셋 준비\n",
    "\n",
    "이 예제에서는 [Registry of Open Data on AWS](https://registry.opendata.aws/fast-ai-nlp/) 퍼블릭 리포지토리에서 **FastAi AG News** 데이터 세트를 다운로드합니다. 이 데이터 세트에는 뉴스 헤드라인과 그에 해당하는 주제 클래스의 표가 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131a0145-9033-4112-a67f-5e229679229e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://fast-ai-nlp/ag_news_csv.tgz to data/ag_news_csv.tgz\n",
      "Done!\n",
      "CPU times: user 84.2 ms, sys: 24.9 ms, total: 109 ms\n",
      "Wall time: 4.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download the AG News data from the Registry of Open Data on AWS.\n",
    "!mkdir -p {local_dir}\n",
    "!aws s3 cp s3://fast-ai-nlp/ag_news_csv.tgz {local_dir} --no-sign-request\n",
    "\n",
    "# Un-tar the AG News data.\n",
    "!tar zxf {local_dir}/ag_news_csv.tgz -C {local_dir}/ --strip-components=1 --no-same-owner\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba225c-14bd-4941-8fa0-a68fe7f5fe6f",
   "metadata": {},
   "source": [
    "데이터를 다운로드하고 추출한 후 아래와 같이 몇 가지 예를 살펴볼 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5369b9a2-c6f8-46ce-9b98-9451817be488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86110</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>Oracle to drop PeopleSoft suit if tender fails</td>\n",
       "      <td>Oracle Corp. notified Delaware's Court of Chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74390</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>NTT DoCoMo, IBM, Intel team to secure mobile d...</td>\n",
       "      <td>With an eye towards making mobile devices and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77491</th>\n",
       "      <td>Sci/Tech</td>\n",
       "      <td>Election Is Crunch Time for U.S. Secret Service</td>\n",
       "      <td>With just days to go before the U.S. president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27497</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Former Celtic striker Larsson on Barcelona bench</td>\n",
       "      <td>Henrik Larsson was left on the bench by Barcel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47492</th>\n",
       "      <td>World</td>\n",
       "      <td>Four Suicides Linked to Child Porn Probe (AP)</td>\n",
       "      <td>AP - The government will press on with a child...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CATEGORY                                              TITLE  \\\n",
       "86110  Sci/Tech     Oracle to drop PeopleSoft suit if tender fails   \n",
       "74390  Sci/Tech  NTT DoCoMo, IBM, Intel team to secure mobile d...   \n",
       "77491  Sci/Tech    Election Is Crunch Time for U.S. Secret Service   \n",
       "27497    Sports   Former Celtic striker Larsson on Barcelona bench   \n",
       "47492     World      Four Suicides Linked to Child Porn Probe (AP)   \n",
       "\n",
       "                                                 CONTENT  \n",
       "86110  Oracle Corp. notified Delaware's Court of Chan...  \n",
       "74390  With an eye towards making mobile devices and ...  \n",
       "77491  With just days to go before the U.S. president...  \n",
       "27497  Henrik Larsson was left on the bench by Barcel...  \n",
       "47492  AP - The government will press on with a child...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"CATEGORY\", \"TITLE\", \"CONTENT\"]\n",
    "# we use the train.csv only\n",
    "df = pd.read_csv(f\"{local_dir}/train.csv\", names=column_names, header=None, delimiter=\",\")\n",
    "# shuffle the DataFrame rows\n",
    "df = df.sample(frac=1, random_state=1337)\n",
    "\n",
    "# Make the (1-indexed) category classes more readable:\n",
    "class_names = [\"Other\", \"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "idx2label = {ix: name for ix, name in enumerate(class_names)}\n",
    "label2idx = {name: ix for ix, name in enumerate(class_names)}\n",
    "\n",
    "df = df.replace({\"CATEGORY\": idx2label})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f56818-09f1-48fc-bd5b-21530e7ef9c5",
   "metadata": {},
   "source": [
    "이번 연습에서는 **아래의 값만 사용하겠습니다**:\n",
    "\n",
    "- 뉴스 기사의 **title**(Headline)을 입력으로 사용합니다.\n",
    "- 예측할 목표 변수로 **category**를 사용합니다.\n",
    "\n",
    "이 데이터 세트에는 아래와 같이 4개의 균등하게 분포된 토픽 클래스가 포함되어 있습니다.\n",
    "\n",
    "> ℹ️ **'Other'는 어떻게 할까요?:** 원시 데이터 세트는 1~4 사이의 숫자로 범주를 나타내며, 우리의 모델은 0부터 시작하는 숫자를 예상하기 때문에, 데이터 준비를 단순하게 유지하고 클래스의 혼란스러운 추가 숫자 표현을 피하기 위해 사용하지 않는 'Other' 클래스를 삽입했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a70b377-ee49-4780-8b32-57db4ee149ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sci/Tech    30000\n",
       "Sports      30000\n",
       "World       30000\n",
       "Business    30000\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CATEGORY\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628acab-0b0b-4b77-9800-8dc154c55249",
   "metadata": {},
   "source": [
    "## 훈련 파라미터 정의\n",
    "\n",
    "[Hugging Face Hub](https://huggingface.co/models)에서 (비교적 작은) 사전 학습된 모델을 미세 조정하고, 낮은 수준의 학습 루프를 처음부터 작성하는 대신 높은 수준의 [Trainer API](https://huggingface.co/docs/transformers/main_classes/trainer)를 사용할 것입니다.\n",
    "\n",
    "아래에서는 학습을 위한 기본 파라미터를 설정하겠습니다.\n",
    "\n",
    "> 🏎️ 이 노트북 내 예제에서는 기본적으로 **저렴한 CPU 전용 컴퓨팅**을 사용하겠습니다. 우리가 훈련하는 모델은 최신 LLM 표준에 따르면 \"소규모\"이지만, 합리적인 시간 내에 완료할 수 있도록 훈련을 매우 일찍 중단해야 합니다.\n",
    ">\n",
    "> 결과 모델은 학습이 매우 부족할 것이며, 동일한 아키텍처가 궁극적으로 도달할 수 있는 것보다 훨씬 덜 정확할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01c772a2-b9f1-4908-b7e0-07e162933fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"amazon/bort\"  # ID of the pre-trained model to start from\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=f\"{local_dir}/model\",  # Where to save trained model snapshots\n",
    "    #logging_dir=f\"{local_dir}/local-logs\",  # Optionally, save logs too\n",
    "    max_steps=500,  # Maximum number of training steps to run\n",
    "    num_train_epochs=3,  # Maximum number of times to loop through the training data\n",
    "    per_device_train_batch_size=16,  # Examples per mini-batch for training\n",
    "    per_device_eval_batch_size=32,  # Examples per mini-batch for validation\n",
    "    evaluation_strategy=\"steps\",  # Run validation every N 'steps' instead of every 'epoch'\n",
    "    eval_steps=100,  # Number of training steps between validation runs\n",
    "    save_strategy=\"steps\",  # Must be same as evaluation_strategy when load_best_model_at_end=True\n",
    "    load_best_model_at_end=True,  # If current model at end is not the best, load the best\n",
    "    metric_for_best_model=\"f1\",  # Use F1 score for judging which model is 'best'\n",
    "    learning_rate=5e-5,  # Initial learning rate (decays over time by default)\n",
    "    warmup_steps=100,  # Number of steps to gradually increase the learning rate from the start\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a37d97-07f7-4985-8b6a-19aa751d1ab4",
   "metadata": {},
   "source": [
    "## 메트릭 정의\n",
    "\n",
    "여기서는 모델이 검증될 때마다 실행되는 [callback function](https://huggingface.co/docs/transformers/main_classes/callback)를 설정하여 학습된 모델의 품질을 측정하는 방법을 정의하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca817667-2bb8-4098-9840-466d42a13d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"micro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a2df25-93e0-4f15-89de-844b291d6862",
   "metadata": {},
   "source": [
    "## 모델 학습 및 유효성 검사\n",
    "\n",
    "이 섹션에서는 기본 모델과 데이터 세트를 로드하고 실제 훈련 및 유효성 검사 프로세스를 실행하겠습니다.\n",
    "\n",
    "먼저, 주어진 'model_id'에 대해 사전 학습된 모델과 함께 제공되는 [tokenizer](https://huggingface.co/docs/transformers/main_classes/tokenizer)를 로드해야 하며, 이는 허깅 페이스 허브에서 자동으로 다운로드됩니다.\n",
    "\n",
    "모델을 설정하는 과정에서 미세 조정할 토픽 클래스의 수를 지정하고 사람이 읽을 수 있는 이름을 설정해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f351c2e7-70ee-4d02-8b28-b1792073b8df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at amazon/bort were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at amazon/bort and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(class_names))\n",
    "model.config.label2id = label2idx\n",
    "model.config.id2label = idx2label\n",
    "\n",
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcabbc33-4f7a-4591-82d2-ec0b07bcb1d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "데이터 세트에 이미 제공된 원시 `train.csv` 및 `test.csv` 파일을 훈련의 인풋으로 사용하겠지만, 먼저 몇 가지 전처리를 설정해야 합니다:\n",
    "\n",
    "- CSV에는 열 헤더가 없으므로, `column_names`를 수동으로 지정해야 합니다.\n",
    "- `tokenizer`는 긴 헤드라인을 모델이 지원하는 최대 길이로 잘라내는 것을 포함하여 원시 텍스트를 모델이 예상하는 (숫자) 인풋으로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9610050f-63d8-43d1-9037-39e75d8bcf65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-669c5756cab07c70/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-01ccb200104327a9/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-669c5756cab07c70/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-d5a77a93d22a4706.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-01ccb200104327a9/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-06bd3785174931e3.arrow\n"
     ]
    }
   ],
   "source": [
    "def preprocess(batch):\n",
    "    \"\"\"Tokenize and pre-process raw examples for training/validation\"\"\"\n",
    "    result = tokenizer(batch[\"title\"], truncation=True)\n",
    "    result[\"label\"] = batch[\"category\"]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Load the raw datasets:\n",
    "raw_train_dataset = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=os.path.join(local_dir, \"train.csv\"),\n",
    "    column_names=[\"category\", \"title\", \"content\"],\n",
    "    split=datasets.Split.ALL,\n",
    ")\n",
    "raw_test_dataset = datasets.load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=os.path.join(local_dir, \"test.csv\"),\n",
    "    column_names=[\"category\", \"title\", \"content\"],\n",
    "    split=datasets.Split.ALL,\n",
    ")\n",
    "\n",
    "# Run the tokenization/pre-processing, keeping only the output fields from preprocess()\n",
    "train_dataset = raw_train_dataset.map(\n",
    "    preprocess, batched=True, batch_size=1000, remove_columns=raw_train_dataset.column_names\n",
    ")\n",
    "test_dataset = raw_test_dataset.map(\n",
    "    preprocess, batched=True, batch_size=1000, remove_columns=raw_test_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427526e0-6fb6-45a0-94a0-9bb755a9f9e4",
   "metadata": {},
   "source": [
    "파라미터와 사전 처리된 데이터가 로드되었으므로 모델을 훈련하고 평가할 준비가 되었습니다.\n",
    "\n",
    "> ⏰ **Note:** 기본 `ml.t3.medium`(2 vCPU + 4 GiB RAM) Studio 인스턴스 유형에서 이 프로세스를 완료하는 데 약 20분이 소요됩니다.\n",
    ">\n",
    "> 기다리는 동안 [SageMaker notebook](Headline%20Classifier%20SageMaker.ipynb)으로 이동하여 이 프로세스가 SageMaker 훈련 작업으로 마이그레이션될 때 어떻게 달라지는지 살펴볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b077dc-5cb7-4945-885b-cfccd49c25d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 120000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 500\n",
      "  Number of trainable parameters = 76162053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-30 15:41:04.069 pytorch-1-13-cpu-py39-ml-t3-medium-9140905751f3e451a2295c86a7c3:1161 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2023-03-30 15:41:04.224 pytorch-1-13-cpu-py39-ml-t3-medium-9140905751f3e451a2295c86a7c3:1161 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 31/500 00:58 < 15:41, 0.50 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create Trainer instance\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer.train()\n",
    "\n",
    "# evaluate model\n",
    "eval_result = trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fd733-4aa9-457c-b369-a5cbcde46768",
   "metadata": {},
   "source": [
    "메트릭에서 볼 수 있듯이 여기에서 학습된 모델은 정확도가 높지 않을 가능성이 높으며, 학습이 종료된 시점에서도 정확도가 빠르게 증가하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e58b2-f792-46e1-b7a3-7613bb9f3184",
   "metadata": {},
   "source": [
    "## 추론에 모델 사용\n",
    "\n",
    "모델이 학습되면 새로운 데이터에 대한 추론에 사용할 준비가 된 것입니다.\n",
    "\n",
    "여기에서는 학습 과정에서 모델이 이미 메모리에 로드되어 있으므로 [Pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines)으로 래핑하여 쉽게 사용할 수 있습니다.\n",
    "\n",
    "아래 셀은 사용자가 직접 뉴스 헤드라인을 입력하고 모델이 실시간으로 분류하도록 할 수 있는 대화형 위젯을 생성합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658acce-6ba1-401c-bf2a-027c227c4db7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = transformers.pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "def classify(text: str) -> dict:\n",
    "    \"\"\"Classify a headline and print the results\"\"\"\n",
    "    print(pipe(text)[0])\n",
    "\n",
    "\n",
    "# Either try out the interactive widget:\n",
    "interaction = widgets.interact_manual(\n",
    "    classify,\n",
    "    text=widgets.Text(\n",
    "        value=\"The markets were bullish after news of the merger\",\n",
    "        placeholder=\"Type a news headline...\",\n",
    "        description=\"Headline:\",\n",
    "        layout=widgets.Layout(width=\"99%\"),\n",
    "    ),\n",
    ")\n",
    "interaction.widget.children[1].description = \"Classify!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe1d76f-4a2e-41ab-b498-e3b8c1611e9d",
   "metadata": {},
   "source": [
    "또는 코드에서 직접 파이프라인을 호출할 수도 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b0acb-f5b9-48b5-b7b3-404ad8158175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classify(\"Retailers are expanding after the recent economic growth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ba7286-50b7-45e7-9a4c-db5d1ba96bcc",
   "metadata": {},
   "source": [
    "## 리뷰\n",
    "\n",
    "이 노트북에서는 일반 Jupyter 환경에서 로컬로 허깅 페이스 트랜스포머를 사용해 텍스트 분류 모델을 훈련하는 방법을 보여드렸습니다.\n",
    "\n",
    "기본 노트북 컴퓨팅 인프라(`ml.t3.medium`)가 상당히 작았기 때문에 훈련에 시간이 오래 걸렸고 결과를 탐색해 보기 위해 조기에 중단해야 했습니다.\n",
    "\n",
    "- 더 나은 모델을 훈련하기 위해 훈련 에포크/단계 컷오프를 확장할 수 있지만, 그러면 프로세스가 더 오래 걸립니다.\n",
    "- 스튜디오 노트북을 더 높은 리소스 인스턴스(GPU 사용 가능)로 전환할 수도 있지만, 그러면 데이터 탐색이나 평가 등 실제로 모델을 학습하지 않는 시간에는 추가 리소스가 유휴 상태가 될 수 있습니다.\n",
    "- 또한 훈련 과정에서 시도한 다양한 매개 변수를 추적하기 위해 실험을 수동으로 기록해야 합니다.\n",
    "\n",
    "다음으로, [SageMaker notebook](Headline%20Classifier%20SageMaker.ipynb)으로 이동하여 필요한 만큼만 비용을 지불하면서 온디맨드 컴퓨팅을 활용하여 더 빠른 훈련과 자동 메타데이터 추적을 수행하는 데 SageMaker 훈련 작업 및 엔드포인트 배포를 활용하는 방법을 보여드리겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a359a-32fb-45df-9cad-c0cd4814e883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
